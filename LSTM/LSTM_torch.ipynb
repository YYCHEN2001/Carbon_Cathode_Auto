{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T12:47:51.989272Z",
     "start_time": "2024-11-25T12:47:50.383157Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:47:52.488478Z",
     "start_time": "2024-11-25T12:47:51.992310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../data/dataset.csv\")\n",
    "data['target_class'] = pd.qcut(data['Cs'], q=10, labels=False)\n",
    "X = data.drop(['Cs', 'target_class'], axis=1)\n",
    "y = data['Cs']\n",
    "stratify_column = data['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=stratify_column)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 将数据转换为张量\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 40\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "fd5981b170952c33",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:47:53.445612Z",
     "start_time": "2024-11-25T12:47:52.641163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_loss import MAPE_Loss, RMSE_Loss\n",
    "# 定义 LSTM 模型\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout=0.3):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.num_layers = len(hidden_sizes)\n",
    "\n",
    "        # Defining multiple LSTM layers with configurable hidden sizes\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        for i in range(self.num_layers):\n",
    "            input_dim = input_size if i == 0 else hidden_sizes[i-1]\n",
    "            lstm_dropout = dropout if self.num_layers > 1 and i < self.num_layers - 1 else 0\n",
    "            self.lstm_layers.append(nn.LSTM(input_dim, hidden_sizes[i], batch_first=True, dropout=lstm_dropout))\n",
    "\n",
    "        # Fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x, seq_lengths=None):\n",
    "        # Initial hidden and cell state for each layer\n",
    "        h0, c0 = [], []\n",
    "        for hidden_size in self.hidden_sizes:\n",
    "            h0.append(torch.zeros(1, x.size(0), hidden_size).to(x.device))\n",
    "            c0.append(torch.zeros(1, x.size(0), hidden_size).to(x.device))\n",
    "\n",
    "        # Forward propagate through each LSTM layer\n",
    "        out = x\n",
    "        for i, lstm in enumerate(self.lstm_layers):\n",
    "            if seq_lengths is not None:\n",
    "                packed_input = nn.utils.rnn.pack_padded_sequence(out, seq_lengths, batch_first=True, enforce_sorted=False)\n",
    "                packed_output, (h, c) = lstm(packed_input, (h0[i], c0[i]))\n",
    "                out, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "            else:\n",
    "                out, (h, c) = lstm(out, (h0[i], c0[i]))\n",
    "\n",
    "        # Decode the hidden state of the last time step using average pooling\n",
    "        out = torch.mean(out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Set model parameters\n",
    "input_size = X_train_scaled.shape[1]  # Number of features per time step\n",
    "hidden_sizes = [48, 64]  # LSTM hidden sizes\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMRegressor(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "# criterion = nn.MSELoss().to(device)\n",
    "# criterion = MAPE_Loss().to(device)\n",
    "criterion = RMSE_Loss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Reshape input for LSTM (batch_size, sequence_length, input_size)\n",
    "def reshape_for_lstm(X):\n",
    "    return X.unsqueeze(1)  # Add a sequence length dimension of 1"
   ],
   "id": "3df9490589a74d9e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:48:22.397764Z",
     "start_time": "2024-11-25T12:47:53.472616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training the model\n",
    "num_epochs = 3000\n",
    "best_loss = float('inf')\n",
    "cumulative_loss = 0.0\n",
    "patience = 30  # 允许的最大连续未改进 epoch 数\n",
    "epochs_without_improvement = 0  # 连续未改进的 epoch 数\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        cumulative_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        average_loss = cumulative_loss / 10\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {average_loss:.4f}')\n",
    "        cumulative_loss = 0.0  # Reset cumulative loss\n",
    "\n",
    "    # 计算验证损失\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            X_batch = reshape_for_lstm(X_batch)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        val_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # 判断验证损失是否改善\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_without_improvement = 0  # 重置计数器\n",
    "        # 保存最佳模型\n",
    "        torch.save(model.state_dict(), \"lstm_best_model.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # 如果验证损失在一定次数的 epoch 内没有改进，则停止训练\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ],
   "id": "1c145a4951631b53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 1194.3050\n",
      "Epoch 20, Average Loss: 1059.3316\n",
      "Epoch 30, Average Loss: 958.4889\n",
      "Epoch 40, Average Loss: 883.2533\n",
      "Epoch 50, Average Loss: 818.0577\n",
      "Epoch 60, Average Loss: 757.9908\n",
      "Epoch 70, Average Loss: 703.0155\n",
      "Epoch 80, Average Loss: 653.0665\n",
      "Epoch 90, Average Loss: 610.1891\n",
      "Epoch 100, Average Loss: 573.5037\n",
      "Epoch 110, Average Loss: 539.5899\n",
      "Epoch 120, Average Loss: 512.4056\n",
      "Epoch 130, Average Loss: 480.4366\n",
      "Epoch 140, Average Loss: 457.8924\n",
      "Epoch 150, Average Loss: 437.9925\n",
      "Epoch 160, Average Loss: 415.2322\n",
      "Epoch 170, Average Loss: 397.9598\n",
      "Epoch 180, Average Loss: 385.3716\n",
      "Epoch 190, Average Loss: 368.5602\n",
      "Epoch 200, Average Loss: 355.5544\n",
      "Epoch 210, Average Loss: 341.7855\n",
      "Epoch 220, Average Loss: 328.5022\n",
      "Epoch 230, Average Loss: 316.1942\n",
      "Epoch 240, Average Loss: 304.8246\n",
      "Epoch 250, Average Loss: 295.3623\n",
      "Epoch 260, Average Loss: 286.0438\n",
      "Epoch 270, Average Loss: 278.5867\n",
      "Epoch 280, Average Loss: 269.3301\n",
      "Epoch 290, Average Loss: 238.4787\n",
      "Epoch 300, Average Loss: 218.9819\n",
      "Epoch 310, Average Loss: 209.9112\n",
      "Epoch 320, Average Loss: 200.9000\n",
      "Epoch 330, Average Loss: 192.9661\n",
      "Epoch 340, Average Loss: 183.7891\n",
      "Epoch 350, Average Loss: 177.1594\n",
      "Epoch 360, Average Loss: 173.3040\n",
      "Epoch 370, Average Loss: 165.8851\n",
      "Epoch 380, Average Loss: 160.7724\n",
      "Epoch 390, Average Loss: 155.8576\n",
      "Epoch 400, Average Loss: 153.8001\n",
      "Epoch 410, Average Loss: 150.0034\n",
      "Epoch 420, Average Loss: 147.3227\n",
      "Epoch 430, Average Loss: 144.0141\n",
      "Epoch 440, Average Loss: 142.1387\n",
      "Epoch 450, Average Loss: 138.8395\n",
      "Epoch 460, Average Loss: 137.5921\n",
      "Epoch 470, Average Loss: 135.4383\n",
      "Epoch 480, Average Loss: 132.5999\n",
      "Epoch 490, Average Loss: 131.4847\n",
      "Epoch 500, Average Loss: 128.1517\n",
      "Epoch 510, Average Loss: 127.8876\n",
      "Epoch 520, Average Loss: 126.1181\n",
      "Epoch 530, Average Loss: 123.2823\n",
      "Epoch 540, Average Loss: 123.7478\n",
      "Epoch 550, Average Loss: 122.1649\n",
      "Epoch 560, Average Loss: 120.0465\n",
      "Epoch 570, Average Loss: 118.2266\n",
      "Epoch 580, Average Loss: 117.6426\n",
      "Epoch 590, Average Loss: 116.3100\n",
      "Epoch 600, Average Loss: 117.0109\n",
      "Epoch 610, Average Loss: 114.0096\n",
      "Epoch 620, Average Loss: 113.6836\n",
      "Epoch 630, Average Loss: 113.1305\n",
      "Epoch 640, Average Loss: 112.5565\n",
      "Epoch 650, Average Loss: 110.9253\n",
      "Epoch 660, Average Loss: 110.3949\n",
      "Epoch 670, Average Loss: 109.8754\n",
      "Epoch 680, Average Loss: 108.1587\n",
      "Epoch 690, Average Loss: 107.5354\n",
      "Epoch 700, Average Loss: 107.9989\n",
      "Epoch 710, Average Loss: 106.2082\n",
      "Epoch 720, Average Loss: 105.5928\n",
      "Epoch 730, Average Loss: 104.5243\n",
      "Epoch 740, Average Loss: 105.3994\n",
      "Epoch 750, Average Loss: 104.2944\n",
      "Epoch 760, Average Loss: 103.6723\n",
      "Epoch 770, Average Loss: 102.0510\n",
      "Epoch 780, Average Loss: 101.0328\n",
      "Epoch 790, Average Loss: 101.9860\n",
      "Epoch 800, Average Loss: 101.1727\n",
      "Epoch 810, Average Loss: 99.7677\n",
      "Epoch 820, Average Loss: 99.2836\n",
      "Epoch 830, Average Loss: 98.4383\n",
      "Epoch 840, Average Loss: 97.8701\n",
      "Epoch 850, Average Loss: 96.8602\n",
      "Epoch 860, Average Loss: 96.1679\n",
      "Epoch 870, Average Loss: 95.8381\n",
      "Epoch 880, Average Loss: 95.9130\n",
      "Epoch 890, Average Loss: 93.2399\n",
      "Early stopping at epoch 893\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:48:24.840337Z",
     "start_time": "2024-11-25T12:48:24.796875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from function import calculate_metrics, metrics_to_dataframe\n",
    "\n",
    "# 加载最佳模型的状态字典\n",
    "model.load_state_dict(torch.load(\"lstm_best_model.pth\", weights_only=True))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 准备训练数据\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_predictions = []\n",
    "    y_train_true = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "        outputs = model(X_batch)\n",
    "        train_predictions.append(outputs.cpu().numpy())\n",
    "        y_train_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "    train_predictions = np.concatenate(train_predictions, axis=0)\n",
    "    y_train_true = np.concatenate(y_train_true, axis=0)\n",
    "\n",
    "    # 计算训练集的指标\n",
    "    train_metrics = calculate_metrics(y_train_true, train_predictions)\n",
    "    print(\"训练集指标:\", train_metrics)\n",
    "\n",
    "    # 准备测试数据\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_predictions = []\n",
    "    y_test_true = []\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = reshape_for_lstm(X_batch)\n",
    "        outputs = model(X_batch)\n",
    "        test_predictions.append(outputs.cpu().numpy())\n",
    "        y_test_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    y_test_true = np.concatenate(y_test_true, axis=0)\n",
    "\n",
    "    # 计算测试集的指标\n",
    "    test_metrics = calculate_metrics(y_test_true, test_predictions)\n",
    "    print(\"测试集指标:\", test_metrics)\n",
    "\n",
    "    # 将结果转换为DataFrame\n",
    "    lstm_metrics = metrics_to_dataframe(\n",
    "        y_train_true, train_predictions,\n",
    "        y_test_true, test_predictions, \"LSTM\").round(3)\n",
    "    lstm_metrics.to_csv('LSTM_metrics.csv', index=False)\n",
    "    print(lstm_metrics)\n"
   ],
   "id": "b8b38ebb7b444f9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集指标: (0.9583463668823242, 4.2290235, 3.8698870688676834, 8.147504)\n",
      "测试集指标: (0.9247881770133972, 6.749187, 8.557173609733582, 10.883815)\n",
      "  model  R2_train  MAE_train  MAPE_train  RMSE_train  R2_test  MAE_test  \\\n",
      "0  LSTM     0.958      4.229        3.87       8.148    0.925     6.749   \n",
      "\n",
      "   MAPE_test  RMSE_test  \n",
      "0      8.557     10.884  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:48:23.105545Z",
     "start_time": "2024-11-25T12:48:23.100205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存预测结果\n",
    "lstm_train = pd.DataFrame({'Actual': y_train_true, 'Predicted': train_predictions.squeeze()})\n",
    "lstm_test = pd.DataFrame({'Actual': y_test_true, 'Predicted': test_predictions.squeeze()})\n",
    "lstm_train.to_csv('lstm_train.csv', index=False)"
   ],
   "id": "89a0b250ede65b92",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
