{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T07:53:33.028675Z",
     "start_time": "2024-12-05T07:53:29.302150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "e7d30d5c108ee240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T07:53:36.518454Z",
     "start_time": "2024-12-05T07:53:34.050785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../../data/dataset_reduced.csv\")\n",
    "data['target_class'] = pd.qcut(data['Cs'], q=10, labels=False)\n",
    "X = data.drop(['Cs', 'target_class'], axis=1)\n",
    "y = data['Cs']\n",
    "stratify_column = data['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=stratify_column)\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the number of material features and test conditions\n",
    "num_material_features = 7\n",
    "num_test_conditions = 2\n",
    "num_features = num_material_features + num_test_conditions\n",
    "\n",
    "# Construct edges: connect each node to its immediate neighbors\n",
    "# edges = []\n",
    "# for i in range(num_material_features):\n",
    "#     if i < num_material_features - 1:\n",
    "#         edges.append([i, i + 1])\n",
    "#         edges.append([i + 1, i])\n",
    "\n",
    "\n",
    "edges = [[0,1],[1,0],[1,2],[1,6],[2,1],[2,3],[3,2],[3,4],[4,3],[4,5],[4,6],[5,4],[6,1],[6,4]]\n",
    "print(edges)\n",
    "\n",
    "# 转换为Tensor\n",
    "edges = np.array(edges).T  # 转置以匹配PyTorch Geometric的edge_index格式\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1) # 确保y是列向量\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)  # 确保y是列向量\n",
    "\n",
    "train_data = Data(x=X_train_tensor, edge_index=edge_index, y=y_train_tensor).to(device)\n",
    "test_data = Data(x=X_test_tensor, edge_index=edge_index, y=y_test_tensor).to(device)\n",
    "\n",
    "train_loader = DataLoader([train_data], batch_size=20, shuffle=True)  # 根据实际数据调整\n",
    "test_loader = DataLoader([test_data], batch_size=20, shuffle=False)  # 根据实际数据调整\n",
    "print(edge_index)"
   ],
   "id": "b295e86f637a2b4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [1, 0], [1, 2], [1, 6], [2, 1], [2, 3], [3, 2], [3, 4], [4, 3], [4, 5], [4, 6], [5, 4], [6, 1], [6, 4]]\n",
      "tensor([[0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 6, 6],\n",
      "        [1, 0, 2, 6, 1, 3, 2, 4, 3, 5, 6, 4, 1, 4]])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T07:54:40.795828Z",
     "start_time": "2024-12-05T07:54:31.639168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_function import RMSE_Loss\n",
    "import torch.optim as optim\n",
    "from GNN_torch import GNNModel\n",
    "\n",
    "model = GNNModel(input_dim=9, hidden_dims=[63, 63, 63], output_dim=1)  # 根据实际输入维度调整\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "criterion = RMSE_Loss().to(device)\n",
    "\n",
    "num_epochs = 3000\n",
    "best_loss = float('inf')\n",
    "patience = 100  # Maximum allowed consecutive epochs without improvement\n",
    "epochs_without_improvement = 0  # Consecutive epochs without improvement\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0  # Initialize cumulative loss for each epoch\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 打印每10个 epoch 的损失\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "    # Calculate validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"gnn_best_model.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Early stopping if no improvement for `patience` epochs\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ],
   "id": "18cb525202dbc92f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/3000], Loss: 59.5441\n",
      "Epoch [20/3000], Loss: 36.2044\n",
      "Epoch [30/3000], Loss: 32.6586\n",
      "Epoch [40/3000], Loss: 28.6444\n",
      "Epoch [50/3000], Loss: 27.1672\n",
      "Epoch [60/3000], Loss: 26.2665\n",
      "Epoch [70/3000], Loss: 25.4403\n",
      "Epoch [80/3000], Loss: 24.6744\n",
      "Epoch [90/3000], Loss: 23.8618\n",
      "Epoch [100/3000], Loss: 23.0050\n",
      "Epoch [110/3000], Loss: 21.9199\n",
      "Epoch [120/3000], Loss: 20.5367\n",
      "Epoch [130/3000], Loss: 18.9610\n",
      "Epoch [140/3000], Loss: 17.3523\n",
      "Epoch [150/3000], Loss: 16.0842\n",
      "Epoch [160/3000], Loss: 15.0903\n",
      "Epoch [170/3000], Loss: 14.2850\n",
      "Epoch [180/3000], Loss: 13.6461\n",
      "Epoch [190/3000], Loss: 12.9954\n",
      "Epoch [200/3000], Loss: 12.5416\n",
      "Epoch [210/3000], Loss: 11.9147\n",
      "Epoch [220/3000], Loss: 11.9125\n",
      "Epoch [230/3000], Loss: 11.2361\n",
      "Epoch [240/3000], Loss: 10.6643\n",
      "Epoch [250/3000], Loss: 10.2286\n",
      "Epoch [260/3000], Loss: 10.2638\n",
      "Epoch [270/3000], Loss: 10.7389\n",
      "Epoch [280/3000], Loss: 8.8822\n",
      "Epoch [290/3000], Loss: 9.5805\n",
      "Epoch [300/3000], Loss: 8.3690\n",
      "Epoch [310/3000], Loss: 8.1146\n",
      "Epoch [320/3000], Loss: 8.1745\n",
      "Epoch [330/3000], Loss: 7.9581\n",
      "Epoch [340/3000], Loss: 7.6851\n",
      "Epoch [350/3000], Loss: 7.6779\n",
      "Epoch [360/3000], Loss: 8.1538\n",
      "Epoch [370/3000], Loss: 8.3402\n",
      "Epoch [380/3000], Loss: 8.0929\n",
      "Epoch [390/3000], Loss: 8.2649\n",
      "Epoch [400/3000], Loss: 7.6810\n",
      "Epoch [410/3000], Loss: 7.0106\n",
      "Epoch [420/3000], Loss: 7.3436\n",
      "Epoch [430/3000], Loss: 7.8019\n",
      "Epoch [440/3000], Loss: 6.7487\n",
      "Epoch [450/3000], Loss: 6.6539\n",
      "Epoch [460/3000], Loss: 6.4513\n",
      "Epoch [470/3000], Loss: 6.5120\n",
      "Epoch [480/3000], Loss: 6.3393\n",
      "Epoch [490/3000], Loss: 6.3922\n",
      "Epoch [500/3000], Loss: 6.4188\n",
      "Epoch [510/3000], Loss: 6.3925\n",
      "Epoch [520/3000], Loss: 6.2961\n",
      "Epoch [530/3000], Loss: 6.1415\n",
      "Epoch [540/3000], Loss: 6.4084\n",
      "Epoch [550/3000], Loss: 6.2226\n",
      "Epoch [560/3000], Loss: 6.1678\n",
      "Epoch [570/3000], Loss: 6.2522\n",
      "Epoch [580/3000], Loss: 6.0593\n",
      "Epoch [590/3000], Loss: 5.9569\n",
      "Epoch [600/3000], Loss: 6.1093\n",
      "Epoch [610/3000], Loss: 6.3092\n",
      "Epoch [620/3000], Loss: 6.4647\n",
      "Epoch [630/3000], Loss: 6.3203\n",
      "Epoch [640/3000], Loss: 6.0348\n",
      "Epoch [650/3000], Loss: 5.9195\n",
      "Epoch [660/3000], Loss: 5.7780\n",
      "Epoch [670/3000], Loss: 5.8924\n",
      "Epoch [680/3000], Loss: 5.6926\n",
      "Epoch [690/3000], Loss: 5.8454\n",
      "Epoch [700/3000], Loss: 5.6017\n",
      "Epoch [710/3000], Loss: 5.6554\n",
      "Epoch [720/3000], Loss: 5.9667\n",
      "Epoch [730/3000], Loss: 5.9747\n",
      "Epoch [740/3000], Loss: 5.6631\n",
      "Epoch [750/3000], Loss: 5.9279\n",
      "Epoch [760/3000], Loss: 5.7013\n",
      "Epoch [770/3000], Loss: 5.7009\n",
      "Epoch [780/3000], Loss: 5.8679\n",
      "Epoch [790/3000], Loss: 5.6196\n",
      "Epoch [800/3000], Loss: 5.3955\n",
      "Epoch [810/3000], Loss: 5.6839\n",
      "Epoch [820/3000], Loss: 5.8388\n",
      "Epoch [830/3000], Loss: 5.8429\n",
      "Epoch [840/3000], Loss: 5.5574\n",
      "Epoch [850/3000], Loss: 5.9173\n",
      "Epoch [860/3000], Loss: 5.8915\n",
      "Epoch [870/3000], Loss: 5.8168\n",
      "Epoch [880/3000], Loss: 5.6124\n",
      "Epoch [890/3000], Loss: 5.3833\n",
      "Epoch [900/3000], Loss: 5.2895\n",
      "Epoch [910/3000], Loss: 5.3674\n",
      "Epoch [920/3000], Loss: 5.6469\n",
      "Epoch [930/3000], Loss: 5.5150\n",
      "Epoch [940/3000], Loss: 5.2708\n",
      "Epoch [950/3000], Loss: 5.6894\n",
      "Epoch [960/3000], Loss: 5.4332\n",
      "Epoch [970/3000], Loss: 5.2843\n",
      "Epoch [980/3000], Loss: 4.9995\n",
      "Epoch [990/3000], Loss: 5.1874\n",
      "Epoch [1000/3000], Loss: 5.1746\n",
      "Epoch [1010/3000], Loss: 5.2003\n",
      "Epoch [1020/3000], Loss: 5.2969\n",
      "Epoch [1030/3000], Loss: 5.1218\n",
      "Epoch [1040/3000], Loss: 5.0515\n",
      "Epoch [1050/3000], Loss: 5.0701\n",
      "Epoch [1060/3000], Loss: 5.0669\n",
      "Epoch [1070/3000], Loss: 5.1266\n",
      "Epoch [1080/3000], Loss: 5.5261\n",
      "Epoch [1090/3000], Loss: 5.4376\n",
      "Epoch [1100/3000], Loss: 5.2194\n",
      "Epoch [1110/3000], Loss: 5.1654\n",
      "Epoch [1120/3000], Loss: 5.2780\n",
      "Epoch [1130/3000], Loss: 5.0217\n",
      "Epoch [1140/3000], Loss: 4.6926\n",
      "Epoch [1150/3000], Loss: 4.7995\n",
      "Epoch [1160/3000], Loss: 5.0626\n",
      "Epoch [1170/3000], Loss: 5.1775\n",
      "Epoch [1180/3000], Loss: 5.1888\n",
      "Epoch [1190/3000], Loss: 5.1503\n",
      "Epoch [1200/3000], Loss: 5.0241\n",
      "Epoch [1210/3000], Loss: 4.8458\n",
      "Epoch [1220/3000], Loss: 4.9610\n",
      "Epoch [1230/3000], Loss: 5.5893\n",
      "Epoch [1240/3000], Loss: 5.0569\n",
      "Epoch [1250/3000], Loss: 4.9329\n",
      "Epoch [1260/3000], Loss: 4.9572\n",
      "Epoch [1270/3000], Loss: 5.1785\n",
      "Epoch [1280/3000], Loss: 5.1737\n",
      "Epoch [1290/3000], Loss: 4.9474\n",
      "Epoch [1300/3000], Loss: 4.9768\n",
      "Epoch [1310/3000], Loss: 4.8526\n",
      "Epoch [1320/3000], Loss: 4.9492\n",
      "Epoch [1330/3000], Loss: 4.9553\n",
      "Epoch [1340/3000], Loss: 4.7945\n",
      "Early stopping at epoch 1343\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T07:54:42.799465Z",
     "start_time": "2024-12-05T07:54:42.783356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from function import metrics_to_dataframe\n",
    "\n",
    "# 加载最佳模型的状态字典\n",
    "model.load_state_dict(torch.load('gnn_best_model.pth', weights_only=True))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 对训练集进行预测\n",
    "    out = model(train_data)\n",
    "    # 对测试集进行预测\n",
    "    test_out = model(test_data)\n",
    "\n",
    "    # 保存指标到CSV文件\n",
    "    metrics_df = metrics_to_dataframe(train_data.y.cpu().numpy(), out.cpu().numpy(),\n",
    "                                      test_data.y.cpu().numpy(), test_out.cpu().numpy(), 'GNN').round(3)\n",
    "    metrics_df.to_csv('gnn_metrics.csv', index=False)\n",
    "\n",
    "metrics_df"
   ],
   "id": "76152af32a546f66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train  R2_test  MAE_test  \\\n",
       "0   GNN     0.984      3.115       3.651       5.103    0.937     6.569   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0      9.354     10.425  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GNN</td>\n",
       "      <td>0.984</td>\n",
       "      <td>3.115</td>\n",
       "      <td>3.651</td>\n",
       "      <td>5.103</td>\n",
       "      <td>0.937</td>\n",
       "      <td>6.569</td>\n",
       "      <td>9.354</td>\n",
       "      <td>10.425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T07:54:47.761587Z",
     "start_time": "2024-12-05T07:54:47.751656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存训练集和测试集的预测结果（包含真实值）\n",
    "train_predictions = pd.DataFrame({'Actual': train_data.y.cpu().detach().numpy().flatten(),\n",
    "                                  'Predicted': model(train_data).cpu().detach().numpy().flatten()})\n",
    "test_predictions = pd.DataFrame({'Actual': test_data.y.cpu().detach().numpy().flatten(),\n",
    "                                 'Predicted': model(test_data).cpu().detach().numpy().flatten()})\n",
    "\n",
    "train_predictions.to_csv('gnn_train_predictions.csv', index=False)\n",
    "test_predictions.to_csv('gnn_test_predictions.csv', index=False)"
   ],
   "id": "e329431250b91a5f",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
