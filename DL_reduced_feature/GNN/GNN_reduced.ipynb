{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:26:27.747541Z",
     "start_time": "2024-12-03T12:26:26.260484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "e7d30d5c108ee240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:26:29.997148Z",
     "start_time": "2024-12-03T12:26:27.751295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../../data/dataset_reduced.csv\")\n",
    "data['target_class'] = pd.qcut(data['Cs'], q=10, labels=False)\n",
    "X = data.drop(['Cs', 'target_class'], axis=1)\n",
    "y = data['Cs']\n",
    "stratify_column = data['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=stratify_column)\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the number of material features and test conditions\n",
    "num_material_features = 7\n",
    "num_test_conditions = 2\n",
    "num_features = num_material_features + num_test_conditions\n",
    "\n",
    "# Construct edges: connect each node to its immediate neighbors\n",
    "# edges = []\n",
    "# for i in range(num_material_features):\n",
    "#     if i < num_material_features - 1:\n",
    "#         edges.append([i, i + 1])\n",
    "#         edges.append([i + 1, i])\n",
    "\n",
    "\n",
    "edges = [[0,1],[1,0],[1,2],[1,6],[2,1],[2,3],[3,2],[3,4],[4,3],[4,5],[4,6],[5,4],[6,1],[6,4]]\n",
    "print(edges)\n",
    "\n",
    "# 转换为Tensor\n",
    "edges = np.array(edges).T  # 转置以匹配PyTorch Geometric的edge_index格式\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1) # 确保y是列向量\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)  # 确保y是列向量\n",
    "\n",
    "train_data = Data(x=X_train_tensor, edge_index=edge_index, y=y_train_tensor).to(device)\n",
    "test_data = Data(x=X_test_tensor, edge_index=edge_index, y=y_test_tensor).to(device)\n",
    "\n",
    "train_loader = DataLoader([train_data], batch_size=20, shuffle=True)  # 根据实际数据调整\n",
    "test_loader = DataLoader([test_data], batch_size=20, shuffle=False)  # 根据实际数据调整\n",
    "print(edge_index)"
   ],
   "id": "b295e86f637a2b4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [1, 0], [1, 2], [1, 6], [2, 1], [2, 3], [3, 2], [3, 4], [4, 3], [4, 5], [4, 6], [5, 4], [6, 1], [6, 4]]\n",
      "tensor([[0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 6, 6],\n",
      "        [1, 0, 2, 6, 1, 3, 2, 4, 3, 5, 6, 4, 1, 4]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:30:58.642153Z",
     "start_time": "2024-12-03T12:30:50.972338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_function import RMSE_Loss\n",
    "import torch.optim as optim\n",
    "from GNN_torch import GNNModel\n",
    "\n",
    "model = GNNModel(input_dim=9, hidden_dims=[63, 63, 63], output_dim=1)  # 根据实际输入维度调整\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "criterion = RMSE_Loss().to(device)\n",
    "\n",
    "num_epochs = 3000\n",
    "best_loss = float('inf')\n",
    "patience = 100  # Maximum allowed consecutive epochs without improvement\n",
    "epochs_without_improvement = 0  # Consecutive epochs without improvement\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0  # Initialize cumulative loss for each epoch\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 打印每10个 epoch 的损失\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "    # Calculate validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"gnn_best_model.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Early stopping if no improvement for `patience` epochs\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ],
   "id": "18cb525202dbc92f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/3000], Loss: 60.9912\n",
      "Epoch [20/3000], Loss: 39.1216\n",
      "Epoch [30/3000], Loss: 32.2569\n",
      "Epoch [40/3000], Loss: 29.5425\n",
      "Epoch [50/3000], Loss: 27.3547\n",
      "Epoch [60/3000], Loss: 26.0738\n",
      "Epoch [70/3000], Loss: 25.0740\n",
      "Epoch [80/3000], Loss: 23.9394\n",
      "Epoch [90/3000], Loss: 22.5713\n",
      "Epoch [100/3000], Loss: 21.0837\n",
      "Epoch [110/3000], Loss: 19.4213\n",
      "Epoch [120/3000], Loss: 17.5301\n",
      "Epoch [130/3000], Loss: 15.8254\n",
      "Epoch [140/3000], Loss: 14.2175\n",
      "Epoch [150/3000], Loss: 13.0544\n",
      "Epoch [160/3000], Loss: 12.2105\n",
      "Epoch [170/3000], Loss: 11.1494\n",
      "Epoch [180/3000], Loss: 10.9045\n",
      "Epoch [190/3000], Loss: 9.9106\n",
      "Epoch [200/3000], Loss: 9.5597\n",
      "Epoch [210/3000], Loss: 9.1320\n",
      "Epoch [220/3000], Loss: 9.2624\n",
      "Epoch [230/3000], Loss: 9.2966\n",
      "Epoch [240/3000], Loss: 8.6577\n",
      "Epoch [250/3000], Loss: 8.0139\n",
      "Epoch [260/3000], Loss: 7.7135\n",
      "Epoch [270/3000], Loss: 7.5043\n",
      "Epoch [280/3000], Loss: 7.2639\n",
      "Epoch [290/3000], Loss: 7.1598\n",
      "Epoch [300/3000], Loss: 6.9845\n",
      "Epoch [310/3000], Loss: 6.9814\n",
      "Epoch [320/3000], Loss: 6.8955\n",
      "Epoch [330/3000], Loss: 8.0509\n",
      "Epoch [340/3000], Loss: 7.4438\n",
      "Epoch [350/3000], Loss: 7.8655\n",
      "Epoch [360/3000], Loss: 7.5205\n",
      "Epoch [370/3000], Loss: 6.3919\n",
      "Epoch [380/3000], Loss: 6.4490\n",
      "Epoch [390/3000], Loss: 6.5500\n",
      "Epoch [400/3000], Loss: 7.2106\n",
      "Epoch [410/3000], Loss: 6.9376\n",
      "Epoch [420/3000], Loss: 6.3946\n",
      "Epoch [430/3000], Loss: 6.0117\n",
      "Epoch [440/3000], Loss: 6.0527\n",
      "Epoch [450/3000], Loss: 6.5195\n",
      "Epoch [460/3000], Loss: 6.6816\n",
      "Epoch [470/3000], Loss: 6.1072\n",
      "Epoch [480/3000], Loss: 5.9398\n",
      "Epoch [490/3000], Loss: 6.4391\n",
      "Epoch [500/3000], Loss: 6.6824\n",
      "Epoch [510/3000], Loss: 6.4163\n",
      "Epoch [520/3000], Loss: 6.0585\n",
      "Epoch [530/3000], Loss: 5.5141\n",
      "Epoch [540/3000], Loss: 5.6777\n",
      "Epoch [550/3000], Loss: 5.7679\n",
      "Epoch [560/3000], Loss: 5.8067\n",
      "Epoch [570/3000], Loss: 5.9247\n",
      "Epoch [580/3000], Loss: 5.6889\n",
      "Epoch [590/3000], Loss: 5.5535\n",
      "Epoch [600/3000], Loss: 5.5619\n",
      "Epoch [610/3000], Loss: 6.4296\n",
      "Epoch [620/3000], Loss: 5.4148\n",
      "Epoch [630/3000], Loss: 6.2245\n",
      "Epoch [640/3000], Loss: 5.8534\n",
      "Epoch [650/3000], Loss: 5.7801\n",
      "Epoch [660/3000], Loss: 5.7258\n",
      "Epoch [670/3000], Loss: 5.8031\n",
      "Epoch [680/3000], Loss: 5.2790\n",
      "Epoch [690/3000], Loss: 5.2528\n",
      "Epoch [700/3000], Loss: 5.6234\n",
      "Epoch [710/3000], Loss: 5.8101\n",
      "Epoch [720/3000], Loss: 5.2917\n",
      "Epoch [730/3000], Loss: 5.3311\n",
      "Epoch [740/3000], Loss: 5.3733\n",
      "Epoch [750/3000], Loss: 5.1696\n",
      "Epoch [760/3000], Loss: 5.5328\n",
      "Epoch [770/3000], Loss: 4.9255\n",
      "Epoch [780/3000], Loss: 5.3854\n",
      "Epoch [790/3000], Loss: 4.9563\n",
      "Epoch [800/3000], Loss: 5.2899\n",
      "Epoch [810/3000], Loss: 4.7230\n",
      "Epoch [820/3000], Loss: 5.5515\n",
      "Epoch [830/3000], Loss: 5.2643\n",
      "Epoch [840/3000], Loss: 5.5712\n",
      "Epoch [850/3000], Loss: 5.2192\n",
      "Epoch [860/3000], Loss: 4.8744\n",
      "Epoch [870/3000], Loss: 5.4769\n",
      "Epoch [880/3000], Loss: 5.9287\n",
      "Epoch [890/3000], Loss: 4.7439\n",
      "Epoch [900/3000], Loss: 4.8738\n",
      "Epoch [910/3000], Loss: 4.7673\n",
      "Epoch [920/3000], Loss: 4.6301\n",
      "Epoch [930/3000], Loss: 4.6527\n",
      "Epoch [940/3000], Loss: 5.3998\n",
      "Epoch [950/3000], Loss: 5.5663\n",
      "Epoch [960/3000], Loss: 5.4047\n",
      "Epoch [970/3000], Loss: 5.3271\n",
      "Epoch [980/3000], Loss: 4.9027\n",
      "Epoch [990/3000], Loss: 4.4804\n",
      "Epoch [1000/3000], Loss: 4.5303\n",
      "Epoch [1010/3000], Loss: 4.4508\n",
      "Epoch [1020/3000], Loss: 5.5268\n",
      "Epoch [1030/3000], Loss: 4.4696\n",
      "Epoch [1040/3000], Loss: 4.4771\n",
      "Epoch [1050/3000], Loss: 4.6366\n",
      "Epoch [1060/3000], Loss: 4.4575\n",
      "Epoch [1070/3000], Loss: 4.4326\n",
      "Epoch [1080/3000], Loss: 4.4395\n",
      "Epoch [1090/3000], Loss: 4.3278\n",
      "Epoch [1100/3000], Loss: 4.2930\n",
      "Epoch [1110/3000], Loss: 4.6807\n",
      "Epoch [1120/3000], Loss: 4.9709\n",
      "Epoch [1130/3000], Loss: 4.9009\n",
      "Epoch [1140/3000], Loss: 4.4973\n",
      "Epoch [1150/3000], Loss: 4.4011\n",
      "Early stopping at epoch 1154\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:31:00.593678Z",
     "start_time": "2024-12-03T12:31:00.578851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from function import metrics_to_dataframe\n",
    "\n",
    "# 加载最佳模型的状态字典\n",
    "model.load_state_dict(torch.load('gnn_best_model.pth', weights_only=True))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 对训练集进行预测\n",
    "    out = model(train_data)\n",
    "    # 对测试集进行预测\n",
    "    test_out = model(test_data)\n",
    "\n",
    "    # 保存指标到CSV文件\n",
    "    metrics_df = metrics_to_dataframe(train_data.y.cpu().numpy(), out.cpu().numpy(),\n",
    "                                      test_data.y.cpu().numpy(), test_out.cpu().numpy(), 'GNN').round(3)\n",
    "    metrics_df.to_csv('gnn_metrics.csv', index=False)\n",
    "\n",
    "metrics_df"
   ],
   "id": "76152af32a546f66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train  R2_test  MAE_test  \\\n",
       "0   GNN     0.986      2.903       3.365        4.82    0.935     6.431   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0      9.185     10.575  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GNN</td>\n",
       "      <td>0.986</td>\n",
       "      <td>2.903</td>\n",
       "      <td>3.365</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.935</td>\n",
       "      <td>6.431</td>\n",
       "      <td>9.185</td>\n",
       "      <td>10.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:26:37.143035Z",
     "start_time": "2024-12-03T12:26:37.132596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存训练集和测试集的预测结果（包含真实值）\n",
    "train_predictions = pd.DataFrame({'Actual': train_data.y.cpu().detach().numpy().flatten(),\n",
    "                                  'Predicted': model(train_data).cpu().detach().numpy().flatten()})\n",
    "test_predictions = pd.DataFrame({'Actual': test_data.y.cpu().detach().numpy().flatten(),\n",
    "                                 'Predicted': model(test_data).cpu().detach().numpy().flatten()})\n",
    "\n",
    "train_predictions.to_csv('gnn_train_predictions.csv', index=False)\n",
    "test_predictions.to_csv('gnn_test_predictions.csv', index=False)"
   ],
   "id": "e329431250b91a5f",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
