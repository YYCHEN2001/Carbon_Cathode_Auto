{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:43:02.142523Z",
     "start_time": "2024-11-21T02:43:00.841574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "e7d30d5c108ee240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 读取数据",
   "id": "31d7c4f1b9247569"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:43:02.758814Z",
     "start_time": "2024-11-21T02:43:02.145661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from function import split_data\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../data/dataset.csv\")\n",
    "X_train, X_test, y_train, y_test = split_data(data)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "b295e86f637a2b4c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 构建图数据对象, 转换数据为图数据结构",
   "id": "e364287c13c7204b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:43:04.095910Z",
     "start_time": "2024-11-21T02:43:02.813818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 材料特性的索引和测试条件的索引\n",
    "material_indices = list(range(7))  # 前七个特性\n",
    "test_indices = list(range(7, 12))  # 后五个条件\n",
    "\n",
    "# 构建边：仅为材料特性之间构建边\n",
    "edges = []\n",
    "for i in material_indices:\n",
    "    for j in material_indices:\n",
    "        if i != j:\n",
    "            edges.append([i, j])\n",
    "\n",
    "# 初始化边列表\n",
    "# edges = []\n",
    "#\n",
    "# # 0和1有边\n",
    "# edges.append([0, 1])\n",
    "# edges.append([1, 0])  # 如果是无向图，需要添加反向边\n",
    "#\n",
    "# # 2-3-4-5相互有边\n",
    "# node_group = [2, 3, 4, 5]\n",
    "# for i in range(len(node_group)):\n",
    "#     for j in range(i + 1, len(node_group)):\n",
    "#         edges.append([node_group[i], node_group[j]])\n",
    "#         edges.append([node_group[j], node_group[i]])  # 如果是无向图，需要添加反向边\n",
    "#\n",
    "# # 0、1、2、3分别与6有边\n",
    "# for node in [0, 1, 2, 3]:\n",
    "#     edges.append([node, 6])\n",
    "#     edges.append([6, node])  # 如果是无向图，需要添加反向边\n",
    "#\n",
    "# # 0和2有边\n",
    "# edges.append([0, 2])\n",
    "# edges.append([2, 0])  # 如果是无向图，需要添加反向边\n",
    "\n",
    "# 转换为Tensor\n",
    "edges = np.array(edges).T  # 转置以匹配PyTorch Geometric的edge_index格式\n",
    "\n",
    "print(edges)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float).view(-1, 1)  # 确保y是列向量\n",
    "\n",
    "# 创建图数据对象\n",
    "train_data = Data(x=X_train_tensor, edge_index=edge_index, y=y_train_tensor).to(device)\n",
    "\n",
    "# 打印数据对象信息，确认构建是否成功\n",
    "print(train_data)"
   ],
   "id": "6fd7f6e086ddd296",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5\n",
      "  6 6 6 6 6 6]\n",
      " [1 2 3 4 5 6 0 2 3 4 5 6 0 1 3 4 5 6 0 1 2 4 5 6 0 1 2 3 5 6 0 1 2 3 4 6\n",
      "  0 1 2 3 4 5]]\n",
      "Data(x=[480, 12], edge_index=[2, 42], y=[480, 1])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 定义模型",
   "id": "6f857b4b31231496"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:43:04.148517Z",
     "start_time": "2024-11-21T02:43:04.112148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn, optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_loss import MAPE_Loss\n",
    "\n",
    "class GNN4TDL(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(GNN4TDL, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, 24)\n",
    "        self.conv2 = GCNConv(24, 48)\n",
    "        self.conv3 = GCNConv(48, 1)\n",
    "        # self.conv4 = GCNConv(24, 1)\n",
    "        # self.conv5 = GCNConv(24, 1)\n",
    "        # self.conv6 = GCNConv(70, 30)\n",
    "        # self.conv7 = GCNConv(30, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.conv4(x, edge_index)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.conv5(x, edge_index)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.conv6(x, edge_index)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.conv7(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GNN4TDL(\n",
    "    input_dim=X_train_scaled.shape[1]\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 定义损失函数\n",
    "mse_loss = nn.MSELoss().to(device)\n",
    "mape_loss = MAPE_Loss().to(device)\n",
    "## 训练模型"
   ],
   "id": "18cb525202dbc92f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T02:43:19.172762Z",
     "start_time": "2024-11-21T02:43:04.162536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 3000\n",
    "best_loss = float('inf')\n",
    "cumulative_loss = 0.0\n",
    "patience = 30  # 允许的最大连续未改进 epoch 数\n",
    "epochs_without_improvement = 0  # 连续未改进的 epoch 数\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.zero_grad()\n",
    "    out = model(train_data)\n",
    "    loss = mape_loss(out, train_data.y)  # Modify as per your loss function, e.g., mape_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cumulative_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        average_loss = cumulative_loss / 10\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {average_loss}')\n",
    "        cumulative_loss = 0.0  # Reset cumulative loss\n",
    "\n",
    "    # 计算验证损失\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 在 GPU 上进行预测\n",
    "        y_val_pred = model(train_data).to(device)\n",
    "        # 验证损失计算时，确保 y_test_tensor 也在同一个设备上\n",
    "        train_data.y = train_data.y.to(device)\n",
    "        val_loss = mape_loss(y_val_pred, train_data.y).item()  # 计算验证损失\n",
    "\n",
    "    # 判断验证损失是否改善\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_without_improvement = 0  # 重置计数器\n",
    "        # 保存最佳模型\n",
    "        torch.save(model.state_dict(), \"gnn4tdl_best_model.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # 如果验证损失在一定次数的 epoch 内没有改进，则停止训练\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ],
   "id": "49aa5bf124c4f90d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 99.74763641357421\n",
      "Epoch 20, Average Loss: 99.03573226928711\n",
      "Epoch 30, Average Loss: 98.26322326660156\n",
      "Epoch 40, Average Loss: 97.36977996826172\n",
      "Epoch 50, Average Loss: 96.26036148071289\n",
      "Epoch 60, Average Loss: 94.83712768554688\n",
      "Epoch 70, Average Loss: 93.00299911499023\n",
      "Epoch 80, Average Loss: 90.64888992309571\n",
      "Epoch 90, Average Loss: 87.6869384765625\n",
      "Epoch 100, Average Loss: 84.31017684936523\n",
      "Epoch 110, Average Loss: 80.70155563354493\n",
      "Epoch 120, Average Loss: 76.93786849975587\n",
      "Epoch 130, Average Loss: 73.09059143066406\n",
      "Epoch 140, Average Loss: 69.05624771118164\n",
      "Epoch 150, Average Loss: 64.86262359619141\n",
      "Epoch 160, Average Loss: 60.77327346801758\n",
      "Epoch 170, Average Loss: 56.97887649536133\n",
      "Epoch 180, Average Loss: 53.389325332641604\n",
      "Epoch 190, Average Loss: 50.094200897216794\n",
      "Epoch 200, Average Loss: 47.20117073059082\n",
      "Epoch 210, Average Loss: 44.70979042053223\n",
      "Epoch 220, Average Loss: 42.61548080444336\n",
      "Epoch 230, Average Loss: 40.909960174560545\n",
      "Epoch 240, Average Loss: 39.49262657165527\n",
      "Epoch 250, Average Loss: 38.219228744506836\n",
      "Epoch 260, Average Loss: 37.0087215423584\n",
      "Epoch 270, Average Loss: 35.89358978271484\n",
      "Epoch 280, Average Loss: 34.882433319091795\n",
      "Epoch 290, Average Loss: 33.95105972290039\n",
      "Epoch 300, Average Loss: 33.09726829528809\n",
      "Epoch 310, Average Loss: 32.36409301757813\n",
      "Epoch 320, Average Loss: 31.719807052612303\n",
      "Epoch 330, Average Loss: 31.132967948913574\n",
      "Epoch 340, Average Loss: 30.611387252807617\n",
      "Epoch 350, Average Loss: 30.124428749084473\n",
      "Epoch 360, Average Loss: 29.664606666564943\n",
      "Epoch 370, Average Loss: 29.250461196899415\n",
      "Epoch 380, Average Loss: 28.86717643737793\n",
      "Epoch 390, Average Loss: 28.50974178314209\n",
      "Epoch 400, Average Loss: 28.183970069885255\n",
      "Epoch 410, Average Loss: 27.87325839996338\n",
      "Epoch 420, Average Loss: 27.58630542755127\n",
      "Epoch 430, Average Loss: 27.318477058410643\n",
      "Epoch 440, Average Loss: 27.06838893890381\n",
      "Epoch 450, Average Loss: 26.830043601989747\n",
      "Epoch 460, Average Loss: 26.60662078857422\n",
      "Epoch 470, Average Loss: 26.393941116333007\n",
      "Epoch 480, Average Loss: 26.185462188720702\n",
      "Epoch 490, Average Loss: 25.98790626525879\n",
      "Epoch 500, Average Loss: 25.796514892578124\n",
      "Epoch 510, Average Loss: 25.6106819152832\n",
      "Epoch 520, Average Loss: 25.43451805114746\n",
      "Epoch 530, Average Loss: 25.260943984985353\n",
      "Epoch 540, Average Loss: 25.083660697937013\n",
      "Epoch 550, Average Loss: 24.900870895385744\n",
      "Epoch 560, Average Loss: 24.730669212341308\n",
      "Epoch 570, Average Loss: 24.567243576049805\n",
      "Epoch 580, Average Loss: 24.407173538208006\n",
      "Epoch 590, Average Loss: 24.247200584411623\n",
      "Epoch 600, Average Loss: 24.082523918151857\n",
      "Epoch 610, Average Loss: 23.916608810424805\n",
      "Epoch 620, Average Loss: 23.745928001403808\n",
      "Epoch 630, Average Loss: 23.572718620300293\n",
      "Epoch 640, Average Loss: 23.392693328857423\n",
      "Epoch 650, Average Loss: 23.216042137145998\n",
      "Epoch 660, Average Loss: 23.041730690002442\n",
      "Epoch 670, Average Loss: 22.869696426391602\n",
      "Epoch 680, Average Loss: 22.698291778564453\n",
      "Epoch 690, Average Loss: 22.5323637008667\n",
      "Epoch 700, Average Loss: 22.373660469055174\n",
      "Epoch 710, Average Loss: 22.216549682617188\n",
      "Epoch 720, Average Loss: 22.058687210083008\n",
      "Epoch 730, Average Loss: 21.897922706604003\n",
      "Epoch 740, Average Loss: 21.739230728149415\n",
      "Epoch 750, Average Loss: 21.582053184509277\n",
      "Epoch 760, Average Loss: 21.424668884277345\n",
      "Epoch 770, Average Loss: 21.267409324645996\n",
      "Epoch 780, Average Loss: 21.110234642028807\n",
      "Epoch 790, Average Loss: 20.951564979553222\n",
      "Epoch 800, Average Loss: 20.791890335083007\n",
      "Epoch 810, Average Loss: 20.63800811767578\n",
      "Epoch 820, Average Loss: 20.486988639831544\n",
      "Epoch 830, Average Loss: 20.337638092041015\n",
      "Epoch 840, Average Loss: 20.195701026916502\n",
      "Epoch 850, Average Loss: 20.057195472717286\n",
      "Epoch 860, Average Loss: 19.91749973297119\n",
      "Epoch 870, Average Loss: 19.773921012878418\n",
      "Epoch 880, Average Loss: 19.628149604797365\n",
      "Epoch 890, Average Loss: 19.47776527404785\n",
      "Epoch 900, Average Loss: 19.324740982055665\n",
      "Epoch 910, Average Loss: 19.175980186462404\n",
      "Epoch 920, Average Loss: 19.03279342651367\n",
      "Epoch 930, Average Loss: 18.89352970123291\n",
      "Epoch 940, Average Loss: 18.754804039001463\n",
      "Epoch 950, Average Loss: 18.61485710144043\n",
      "Epoch 960, Average Loss: 18.47372703552246\n",
      "Epoch 970, Average Loss: 18.33929557800293\n",
      "Epoch 980, Average Loss: 18.20087890625\n",
      "Epoch 990, Average Loss: 18.06355724334717\n",
      "Epoch 1000, Average Loss: 17.93435935974121\n",
      "Epoch 1010, Average Loss: 17.808719062805174\n",
      "Epoch 1020, Average Loss: 17.683777618408204\n",
      "Epoch 1030, Average Loss: 17.55888843536377\n",
      "Epoch 1040, Average Loss: 17.431330108642577\n",
      "Epoch 1050, Average Loss: 17.303705596923827\n",
      "Epoch 1060, Average Loss: 17.17901020050049\n",
      "Epoch 1070, Average Loss: 17.051566696166994\n",
      "Epoch 1080, Average Loss: 16.92247829437256\n",
      "Epoch 1090, Average Loss: 16.80278606414795\n",
      "Epoch 1100, Average Loss: 16.687874603271485\n",
      "Epoch 1110, Average Loss: 16.57159423828125\n",
      "Epoch 1120, Average Loss: 16.45354804992676\n",
      "Epoch 1130, Average Loss: 16.337902450561522\n",
      "Epoch 1140, Average Loss: 16.223448753356934\n",
      "Epoch 1150, Average Loss: 16.118041610717775\n",
      "Epoch 1160, Average Loss: 16.014247798919676\n",
      "Epoch 1170, Average Loss: 15.906150245666504\n",
      "Epoch 1180, Average Loss: 15.802129173278809\n",
      "Epoch 1190, Average Loss: 15.707355117797851\n",
      "Epoch 1200, Average Loss: 15.613803005218506\n",
      "Epoch 1210, Average Loss: 15.529963970184326\n",
      "Epoch 1220, Average Loss: 15.436140537261963\n",
      "Epoch 1230, Average Loss: 15.345352745056152\n",
      "Epoch 1240, Average Loss: 15.255278587341309\n",
      "Epoch 1250, Average Loss: 15.163034629821777\n",
      "Epoch 1260, Average Loss: 15.07737627029419\n",
      "Epoch 1270, Average Loss: 14.996684265136718\n",
      "Epoch 1280, Average Loss: 14.917060089111327\n",
      "Epoch 1290, Average Loss: 14.833176326751708\n",
      "Epoch 1300, Average Loss: 14.750380706787109\n",
      "Epoch 1310, Average Loss: 14.66563539505005\n",
      "Epoch 1320, Average Loss: 14.580522632598877\n",
      "Epoch 1330, Average Loss: 14.497091102600098\n",
      "Epoch 1340, Average Loss: 14.415270805358887\n",
      "Epoch 1350, Average Loss: 14.333716869354248\n",
      "Epoch 1360, Average Loss: 14.248457908630371\n",
      "Epoch 1370, Average Loss: 14.166629219055176\n",
      "Epoch 1380, Average Loss: 14.085455799102784\n",
      "Epoch 1390, Average Loss: 14.000717258453369\n",
      "Epoch 1400, Average Loss: 13.920456504821777\n",
      "Epoch 1410, Average Loss: 13.84005527496338\n",
      "Epoch 1420, Average Loss: 13.768711757659911\n",
      "Epoch 1430, Average Loss: 13.701168632507324\n",
      "Epoch 1440, Average Loss: 13.619026947021485\n",
      "Epoch 1450, Average Loss: 13.547262191772461\n",
      "Epoch 1460, Average Loss: 13.479399108886719\n",
      "Epoch 1470, Average Loss: 13.416692543029786\n",
      "Epoch 1480, Average Loss: 13.355239963531494\n",
      "Epoch 1490, Average Loss: 13.29089412689209\n",
      "Epoch 1500, Average Loss: 13.226441955566406\n",
      "Epoch 1510, Average Loss: 13.16332187652588\n",
      "Epoch 1520, Average Loss: 13.102316951751709\n",
      "Epoch 1530, Average Loss: 13.052943706512451\n",
      "Epoch 1540, Average Loss: 12.994166374206543\n",
      "Epoch 1550, Average Loss: 12.94000597000122\n",
      "Epoch 1560, Average Loss: 12.887182998657227\n",
      "Epoch 1570, Average Loss: 12.838265419006348\n",
      "Epoch 1580, Average Loss: 12.790997219085693\n",
      "Epoch 1590, Average Loss: 12.738449382781983\n",
      "Epoch 1600, Average Loss: 12.684040069580078\n",
      "Epoch 1610, Average Loss: 12.634334087371826\n",
      "Epoch 1620, Average Loss: 12.587897396087646\n",
      "Epoch 1630, Average Loss: 12.541385936737061\n",
      "Epoch 1640, Average Loss: 12.497319602966309\n",
      "Epoch 1650, Average Loss: 12.442792797088623\n",
      "Epoch 1660, Average Loss: 12.392104816436767\n",
      "Epoch 1670, Average Loss: 12.33790397644043\n",
      "Epoch 1680, Average Loss: 12.285698795318604\n",
      "Epoch 1690, Average Loss: 12.235257053375244\n",
      "Epoch 1700, Average Loss: 12.190553569793702\n",
      "Epoch 1710, Average Loss: 12.148343563079834\n",
      "Epoch 1720, Average Loss: 12.09577112197876\n",
      "Epoch 1730, Average Loss: 12.04592227935791\n",
      "Epoch 1740, Average Loss: 11.999431133270264\n",
      "Epoch 1750, Average Loss: 11.95509376525879\n",
      "Epoch 1760, Average Loss: 11.913846492767334\n",
      "Epoch 1770, Average Loss: 11.880540466308593\n",
      "Epoch 1780, Average Loss: 11.841272449493408\n",
      "Epoch 1790, Average Loss: 11.790597724914551\n",
      "Epoch 1800, Average Loss: 11.75222864151001\n",
      "Epoch 1810, Average Loss: 11.712316799163819\n",
      "Epoch 1820, Average Loss: 11.676517772674561\n",
      "Epoch 1830, Average Loss: 11.636638355255126\n",
      "Epoch 1840, Average Loss: 11.5984468460083\n",
      "Epoch 1850, Average Loss: 11.566056632995606\n",
      "Epoch 1860, Average Loss: 11.534695434570313\n",
      "Epoch 1870, Average Loss: 11.500803470611572\n",
      "Epoch 1880, Average Loss: 11.46833257675171\n",
      "Epoch 1890, Average Loss: 11.443015956878662\n",
      "Epoch 1900, Average Loss: 11.41173095703125\n",
      "Epoch 1910, Average Loss: 11.37752571105957\n",
      "Epoch 1920, Average Loss: 11.348038291931152\n",
      "Epoch 1930, Average Loss: 11.31555995941162\n",
      "Epoch 1940, Average Loss: 11.285183334350586\n",
      "Epoch 1950, Average Loss: 11.25307388305664\n",
      "Epoch 1960, Average Loss: 11.223514175415039\n",
      "Epoch 1970, Average Loss: 11.197770023345948\n",
      "Epoch 1980, Average Loss: 11.165832233428954\n",
      "Epoch 1990, Average Loss: 11.134545230865479\n",
      "Epoch 2000, Average Loss: 11.106184673309325\n",
      "Epoch 2010, Average Loss: 11.081407737731933\n",
      "Epoch 2020, Average Loss: 11.050611019134521\n",
      "Epoch 2030, Average Loss: 11.025666618347168\n",
      "Epoch 2040, Average Loss: 10.994388484954834\n",
      "Epoch 2050, Average Loss: 10.968434810638428\n",
      "Epoch 2060, Average Loss: 10.942437076568604\n",
      "Epoch 2070, Average Loss: 10.917952156066894\n",
      "Epoch 2080, Average Loss: 10.891875267028809\n",
      "Epoch 2090, Average Loss: 10.864419746398926\n",
      "Epoch 2100, Average Loss: 10.84032745361328\n",
      "Epoch 2110, Average Loss: 10.81682014465332\n",
      "Epoch 2120, Average Loss: 10.792299461364745\n",
      "Epoch 2130, Average Loss: 10.768810653686524\n",
      "Epoch 2140, Average Loss: 10.744097900390624\n",
      "Epoch 2150, Average Loss: 10.721238136291504\n",
      "Epoch 2160, Average Loss: 10.697104167938232\n",
      "Epoch 2170, Average Loss: 10.668932914733887\n",
      "Epoch 2180, Average Loss: 10.646321773529053\n",
      "Epoch 2190, Average Loss: 10.618797397613525\n",
      "Epoch 2200, Average Loss: 10.596723556518555\n",
      "Epoch 2210, Average Loss: 10.579998970031738\n",
      "Epoch 2220, Average Loss: 10.550663566589355\n",
      "Epoch 2230, Average Loss: 10.531035709381104\n",
      "Epoch 2240, Average Loss: 10.505935287475586\n",
      "Epoch 2250, Average Loss: 10.483758926391602\n",
      "Epoch 2260, Average Loss: 10.464507102966309\n",
      "Epoch 2270, Average Loss: 10.440433692932128\n",
      "Epoch 2280, Average Loss: 10.418180370330811\n",
      "Epoch 2290, Average Loss: 10.396423053741454\n",
      "Epoch 2300, Average Loss: 10.372741603851319\n",
      "Epoch 2310, Average Loss: 10.34870491027832\n",
      "Epoch 2320, Average Loss: 10.330453014373779\n",
      "Epoch 2330, Average Loss: 10.30743055343628\n",
      "Epoch 2340, Average Loss: 10.293955516815185\n",
      "Epoch 2350, Average Loss: 10.268185806274413\n",
      "Epoch 2360, Average Loss: 10.2437237739563\n",
      "Epoch 2370, Average Loss: 10.221553516387939\n",
      "Epoch 2380, Average Loss: 10.198147392272949\n",
      "Epoch 2390, Average Loss: 10.18225793838501\n",
      "Epoch 2400, Average Loss: 10.164268302917481\n",
      "Epoch 2410, Average Loss: 10.146464538574218\n",
      "Epoch 2420, Average Loss: 10.13138132095337\n",
      "Epoch 2430, Average Loss: 10.110743522644043\n",
      "Epoch 2440, Average Loss: 10.093696212768554\n",
      "Epoch 2450, Average Loss: 10.078919410705566\n",
      "Epoch 2460, Average Loss: 10.059570693969727\n",
      "Epoch 2470, Average Loss: 10.04270248413086\n",
      "Epoch 2480, Average Loss: 10.024348831176757\n",
      "Epoch 2490, Average Loss: 9.998106384277344\n",
      "Epoch 2500, Average Loss: 9.982173728942872\n",
      "Epoch 2510, Average Loss: 9.96889419555664\n",
      "Epoch 2520, Average Loss: 9.94485969543457\n",
      "Epoch 2530, Average Loss: 9.925618743896484\n",
      "Epoch 2540, Average Loss: 9.911280918121339\n",
      "Epoch 2550, Average Loss: 9.887636756896972\n",
      "Epoch 2560, Average Loss: 9.86462469100952\n",
      "Epoch 2570, Average Loss: 9.842455005645752\n",
      "Epoch 2580, Average Loss: 9.81833848953247\n",
      "Epoch 2590, Average Loss: 9.805624961853027\n",
      "Epoch 2600, Average Loss: 9.78116340637207\n",
      "Epoch 2610, Average Loss: 9.762826251983643\n",
      "Epoch 2620, Average Loss: 9.742868041992187\n",
      "Epoch 2630, Average Loss: 9.721603775024414\n",
      "Epoch 2640, Average Loss: 9.701128578186035\n",
      "Epoch 2650, Average Loss: 9.687709331512451\n",
      "Epoch 2660, Average Loss: 9.66672716140747\n",
      "Epoch 2670, Average Loss: 9.642803573608399\n",
      "Epoch 2680, Average Loss: 9.629718399047851\n",
      "Epoch 2690, Average Loss: 9.612764453887939\n",
      "Epoch 2700, Average Loss: 9.597112274169922\n",
      "Epoch 2710, Average Loss: 9.575838661193847\n",
      "Epoch 2720, Average Loss: 9.564024925231934\n",
      "Epoch 2730, Average Loss: 9.548986625671386\n",
      "Epoch 2740, Average Loss: 9.534685325622558\n",
      "Epoch 2750, Average Loss: 9.520359802246094\n",
      "Epoch 2760, Average Loss: 9.505494499206543\n",
      "Epoch 2770, Average Loss: 9.488675212860107\n",
      "Epoch 2780, Average Loss: 9.47910213470459\n",
      "Epoch 2790, Average Loss: 9.460995101928711\n",
      "Epoch 2800, Average Loss: 9.445988273620605\n",
      "Epoch 2810, Average Loss: 9.43506669998169\n",
      "Epoch 2820, Average Loss: 9.418062305450439\n",
      "Epoch 2830, Average Loss: 9.399467468261719\n",
      "Epoch 2840, Average Loss: 9.386966705322266\n",
      "Epoch 2850, Average Loss: 9.36569423675537\n",
      "Epoch 2860, Average Loss: 9.35324592590332\n",
      "Epoch 2870, Average Loss: 9.339577198028564\n",
      "Epoch 2880, Average Loss: 9.315743446350098\n",
      "Epoch 2890, Average Loss: 9.300434970855713\n",
      "Epoch 2900, Average Loss: 9.28018569946289\n",
      "Epoch 2910, Average Loss: 9.263008403778077\n",
      "Epoch 2920, Average Loss: 9.24842700958252\n",
      "Epoch 2930, Average Loss: 9.23031759262085\n",
      "Epoch 2940, Average Loss: 9.204062175750732\n",
      "Epoch 2950, Average Loss: 9.185238552093505\n",
      "Epoch 2960, Average Loss: 9.168570613861084\n",
      "Epoch 2970, Average Loss: 9.147746562957764\n",
      "Epoch 2980, Average Loss: 9.132991790771484\n",
      "Epoch 2990, Average Loss: 9.109178352355958\n",
      "Epoch 3000, Average Loss: 9.09185209274292\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6.构建测试集图数据对象",
   "id": "3e942a1212ab0648"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from function import metrics_to_dataframe, calculate_metrics\n",
    "\n",
    "# 加载最佳模型的状态字典\n",
    "model.load_state_dict(torch.load('gnn4tdl_best_model.pth', weights_only=True))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# 转换测试数据为张量\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float).view(-1, 1)  # 确保y是列向量\n",
    "\n",
    "# 创建测试集图数据对象\n",
    "test_data = Data(x=X_test_tensor, edge_index=edge_index, y=y_test_tensor).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 对训练集进行预测\n",
    "    out = model(train_data)\n",
    "    print(\"训练集预测结果:\")\n",
    "    print(out)\n",
    "\n",
    "    # 计算训练集的指标\n",
    "    train_metrics = calculate_metrics(train_data.y.cpu().numpy(), out.cpu().numpy())\n",
    "    print(\"训练集指标:\", train_metrics)\n",
    "\n",
    "    # 对测试集进行预测\n",
    "    test_out = model(test_data)\n",
    "    print(\"测试集预测结果:\")\n",
    "    print(test_out)\n",
    "\n",
    "    # 计算测试集的指标\n",
    "    test_metrics = calculate_metrics(test_data.y.cpu().numpy(), test_out.cpu().numpy())\n",
    "    print(\"测试集指标:\", test_metrics)\n",
    "\n",
    "    # 保存指标到CSV文件\n",
    "    metrics_df = metrics_to_dataframe(train_data.y.cpu().numpy(), out.cpu().numpy(),\n",
    "                                      test_data.y.cpu().numpy(), test_out.cpu().numpy(), 'GNN').round(3)\n",
    "    metrics_df.to_csv('gnn4tdl_metrics.csv', index=False)\n",
    "\n",
    "    print(metrics_df)\n"
   ],
   "id": "e329431250b91a5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 保存训练集和测试集的预测结果（包含真实值）\n",
    "train_predictions = pd.DataFrame({'Actual': train_data.y.cpu().detach().numpy().flatten(),\n",
    "                                  'Predicted': model(train_data).cpu().detach().numpy().flatten()})\n",
    "test_predictions = pd.DataFrame({'Actual': test_data.y.cpu().detach().numpy().flatten(),\n",
    "                                 'Predicted': model(test_data).cpu().detach().numpy().flatten()})\n",
    "\n",
    "train_predictions.to_csv('gnn4tdl_train_predictions.csv', index=False)\n",
    "test_predictions.to_csv('gnn4tdl_test_predictions.csv', index=False)"
   ],
   "id": "7732208f951e52fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
