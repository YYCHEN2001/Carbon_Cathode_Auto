{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 准备数据",
   "id": "483dc5fd0971e2b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:28:58.737417Z",
     "start_time": "2024-12-03T12:28:57.166943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "8874c47a571954c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:28:59.167001Z",
     "start_time": "2024-12-03T12:28:58.739448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../../data/dataset_reduced.csv\")\n",
    "data['target_class'] = pd.qcut(data['Cs'], q=10, labels=False)\n",
    "X = data.drop(['Cs', 'target_class'], axis=1)\n",
    "y = data['Cs']\n",
    "stratify_column = data['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=stratify_column)\n",
    "\n",
    "X_train_categ = X_train.iloc[:, 7].values  # 第九列为类别特征\n",
    "X_train_cont = np.delete(X_train, 7, axis=1)  # 删除第九列，其他为连续特征"
   ],
   "id": "544d2bb78075f78f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:28:59.300662Z",
     "start_time": "2024-12-03T12:28:59.225345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将 NumPy 数组转换为 PyTorch 张量\n",
    "X_train_categ_tensor = torch.tensor(X_train_categ, dtype=torch.long)  # 类别特征需要使用长整型\n",
    "X_train_categ_tensor = X_train_categ_tensor.unsqueeze(1).to(device)  # 在最后一个维度添加1\n",
    "X_train_cont_tensor = torch.tensor(X_train_cont, dtype=torch.float).to(device)  # 连续特征使用浮点型\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)  # 对于回归问题，通常使用浮点数\n",
    "y_train_tensor = y_train_tensor.unsqueeze(1).to(device)\n",
    "\n",
    "# 计算连续特征的均值和标准差\n",
    "mean = X_train_cont_tensor.mean(dim=0)\n",
    "std = X_train_cont_tensor.std(dim=0)\n",
    "continuous_mean_std = torch.stack([mean, std], dim=1).to(device)\n",
    "\n",
    "# 处理测试集\n",
    "X_test_categ = X_test.iloc[:, 7].values\n",
    "X_test_cont = np.delete(X_test, 7, axis=1)\n",
    "X_test_categ_tensor = torch.tensor(X_test_categ, dtype=torch.long)\n",
    "X_test_categ_tensor = X_test_categ_tensor.unsqueeze(1).to(device)\n",
    "X_test_cont_tensor = torch.tensor(X_test_cont, dtype=torch.float).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)\n",
    "y_test_tensor = y_test_tensor.unsqueeze(1).to(device)"
   ],
   "id": "3499816898be9093",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 定义模型",
   "id": "53feb800f58be3f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:29:00.194871Z",
     "start_time": "2024-12-03T12:28:59.421298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "from torch_function import MAE_Loss\n",
    "\n",
    "# 我们有9个特征，其中有1个类别特征，8个连续值特征\n",
    "# 类别特征每个有2个唯一值\n",
    "categories = (2,)\n",
    "num_continuous = 8\n",
    "\n",
    "# 初始化 TabTransformer 模型\n",
    "model = TabTransformer(\n",
    "    categories=categories,\n",
    "    num_continuous=num_continuous,\n",
    "    dim=18,  # 默认维度为32\n",
    "    dim_out=1,  # 回归问题的输出维度为1\n",
    "    depth=8,  # 默认深度为6\n",
    "    heads=8,  # 注意力机制的头数\n",
    "    attn_dropout=0.01,  # 注意力机制的dropout\n",
    "    ff_dropout=0.01,  # 前馈网络的的dropout\n",
    "    mlp_hidden_mults=(1, 4, 12, 1),  # MLP隐藏层的倍数\n",
    "    mlp_act=nn.ReLU(),  # MLP的激活函数, 默认为ReLU\n",
    "    continuous_mean_std=continuous_mean_std,  # 连续值的均值和标准差\n",
    ")\n",
    "\n",
    "# 将模型移动到 GPU\n",
    "model.to(device)\n",
    "\n",
    "# 初始化损失函数\n",
    "criterion = MAE_Loss().to(device)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "f3b60050a04f7e4f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练模型",
   "id": "19f0115a86873316"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:29:50.409838Z",
     "start_time": "2024-12-03T12:29:00.269949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练循环\n",
    "num_epochs = 3000\n",
    "patience = 100  # 允许的最大连续未改进 epoch 数\n",
    "epochs_without_improvement = 0  # 连续未改进的 epoch 数\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    model.zero_grad()\n",
    "    outputs = model(X_train_categ_tensor, X_train_cont_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)  # 使用MSE损失函数\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss:.4f}')\n",
    "\n",
    "    # 计算验证损失\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_train_categ_tensor, X_train_cont_tensor).to(device)\n",
    "        y_train_tensor = y_train_tensor.to(device)\n",
    "        val_loss = criterion(y_val_pred, y_train_tensor).item()\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"tab_transformer_best_model_hidden1241.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ],
   "id": "8f283be2c8de26be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 88.8217\n",
      "Epoch 20, Loss: 71.4939\n",
      "Epoch 30, Loss: 43.1803\n",
      "Epoch 40, Loss: 35.2271\n",
      "Epoch 50, Loss: 32.3522\n",
      "Epoch 60, Loss: 31.0799\n",
      "Epoch 70, Loss: 30.2905\n",
      "Epoch 80, Loss: 30.2007\n",
      "Epoch 90, Loss: 30.1266\n",
      "Epoch 100, Loss: 29.9553\n",
      "Epoch 110, Loss: 29.9256\n",
      "Epoch 120, Loss: 29.7320\n",
      "Epoch 130, Loss: 29.5943\n",
      "Epoch 140, Loss: 29.5612\n",
      "Epoch 150, Loss: 29.2606\n",
      "Epoch 160, Loss: 29.1201\n",
      "Epoch 170, Loss: 28.9964\n",
      "Epoch 180, Loss: 28.7370\n",
      "Epoch 190, Loss: 28.4926\n",
      "Epoch 200, Loss: 28.1645\n",
      "Epoch 210, Loss: 27.6468\n",
      "Epoch 220, Loss: 27.1129\n",
      "Epoch 230, Loss: 26.4438\n",
      "Epoch 240, Loss: 25.5785\n",
      "Epoch 250, Loss: 24.6552\n",
      "Epoch 260, Loss: 23.8551\n",
      "Epoch 270, Loss: 23.2414\n",
      "Epoch 280, Loss: 22.8040\n",
      "Epoch 290, Loss: 22.6523\n",
      "Epoch 300, Loss: 22.0220\n",
      "Epoch 310, Loss: 22.1165\n",
      "Epoch 320, Loss: 21.7318\n",
      "Epoch 330, Loss: 21.6486\n",
      "Epoch 340, Loss: 21.5430\n",
      "Epoch 350, Loss: 21.5381\n",
      "Epoch 360, Loss: 21.5023\n",
      "Epoch 370, Loss: 21.3251\n",
      "Epoch 380, Loss: 21.2013\n",
      "Epoch 390, Loss: 21.0922\n",
      "Epoch 400, Loss: 20.9923\n",
      "Epoch 410, Loss: 20.9609\n",
      "Epoch 420, Loss: 20.9209\n",
      "Epoch 430, Loss: 20.7213\n",
      "Epoch 440, Loss: 20.5804\n",
      "Epoch 450, Loss: 20.3226\n",
      "Epoch 460, Loss: 20.2418\n",
      "Epoch 470, Loss: 20.1151\n",
      "Epoch 480, Loss: 19.9329\n",
      "Epoch 490, Loss: 19.7562\n",
      "Epoch 500, Loss: 19.6238\n",
      "Epoch 510, Loss: 19.4139\n",
      "Epoch 520, Loss: 19.0553\n",
      "Epoch 530, Loss: 18.6571\n",
      "Epoch 540, Loss: 18.2529\n",
      "Epoch 550, Loss: 17.7745\n",
      "Epoch 560, Loss: 17.4635\n",
      "Epoch 570, Loss: 17.0732\n",
      "Epoch 580, Loss: 16.4739\n",
      "Epoch 590, Loss: 16.2928\n",
      "Epoch 600, Loss: 15.9547\n",
      "Epoch 610, Loss: 15.4286\n",
      "Epoch 620, Loss: 15.2618\n",
      "Epoch 630, Loss: 14.8938\n",
      "Epoch 640, Loss: 14.8469\n",
      "Epoch 650, Loss: 14.4059\n",
      "Epoch 660, Loss: 14.3633\n",
      "Epoch 670, Loss: 13.9675\n",
      "Epoch 680, Loss: 13.9473\n",
      "Epoch 690, Loss: 13.8239\n",
      "Epoch 700, Loss: 13.5785\n",
      "Epoch 710, Loss: 13.3915\n",
      "Epoch 720, Loss: 13.2138\n",
      "Epoch 730, Loss: 13.1015\n",
      "Epoch 740, Loss: 12.9715\n",
      "Epoch 750, Loss: 12.7901\n",
      "Epoch 760, Loss: 12.7062\n",
      "Epoch 770, Loss: 12.6532\n",
      "Epoch 780, Loss: 12.3903\n",
      "Epoch 790, Loss: 12.3558\n",
      "Epoch 800, Loss: 12.1612\n",
      "Epoch 810, Loss: 11.9940\n",
      "Epoch 820, Loss: 11.9534\n",
      "Epoch 830, Loss: 11.6939\n",
      "Epoch 840, Loss: 11.5545\n",
      "Epoch 850, Loss: 11.4127\n",
      "Epoch 860, Loss: 11.3137\n",
      "Epoch 870, Loss: 11.0765\n",
      "Epoch 880, Loss: 11.3555\n",
      "Epoch 890, Loss: 11.1468\n",
      "Epoch 900, Loss: 10.9822\n",
      "Epoch 910, Loss: 11.1122\n",
      "Epoch 920, Loss: 10.7335\n",
      "Epoch 930, Loss: 10.5762\n",
      "Epoch 940, Loss: 10.5634\n",
      "Epoch 950, Loss: 10.3682\n",
      "Epoch 960, Loss: 10.3233\n",
      "Epoch 970, Loss: 10.3081\n",
      "Epoch 980, Loss: 10.2745\n",
      "Epoch 990, Loss: 10.3286\n",
      "Epoch 1000, Loss: 9.8443\n",
      "Epoch 1010, Loss: 9.8541\n",
      "Epoch 1020, Loss: 9.9736\n",
      "Epoch 1030, Loss: 9.7456\n",
      "Epoch 1040, Loss: 9.5760\n",
      "Epoch 1050, Loss: 9.6059\n",
      "Epoch 1060, Loss: 9.3318\n",
      "Epoch 1070, Loss: 9.3021\n",
      "Epoch 1080, Loss: 9.2174\n",
      "Epoch 1090, Loss: 8.9991\n",
      "Epoch 1100, Loss: 9.6726\n",
      "Epoch 1110, Loss: 9.2396\n",
      "Epoch 1120, Loss: 8.7728\n",
      "Epoch 1130, Loss: 8.7440\n",
      "Epoch 1140, Loss: 8.8470\n",
      "Epoch 1150, Loss: 8.6703\n",
      "Epoch 1160, Loss: 8.7830\n",
      "Epoch 1170, Loss: 8.8244\n",
      "Epoch 1180, Loss: 8.4293\n",
      "Epoch 1190, Loss: 8.3401\n",
      "Epoch 1200, Loss: 8.3098\n",
      "Epoch 1210, Loss: 8.2709\n",
      "Epoch 1220, Loss: 8.2450\n",
      "Epoch 1230, Loss: 8.0939\n",
      "Epoch 1240, Loss: 8.0617\n",
      "Epoch 1250, Loss: 8.1482\n",
      "Epoch 1260, Loss: 8.2089\n",
      "Epoch 1270, Loss: 8.1227\n",
      "Epoch 1280, Loss: 8.6103\n",
      "Epoch 1290, Loss: 8.0790\n",
      "Epoch 1300, Loss: 8.0496\n",
      "Epoch 1310, Loss: 8.0743\n",
      "Epoch 1320, Loss: 8.2093\n",
      "Epoch 1330, Loss: 7.6939\n",
      "Epoch 1340, Loss: 8.3169\n",
      "Epoch 1350, Loss: 7.8839\n",
      "Epoch 1360, Loss: 7.7719\n",
      "Epoch 1370, Loss: 7.7684\n",
      "Epoch 1380, Loss: 8.0502\n",
      "Epoch 1390, Loss: 7.8138\n",
      "Epoch 1400, Loss: 7.6888\n",
      "Epoch 1410, Loss: 7.6704\n",
      "Epoch 1420, Loss: 7.4990\n",
      "Epoch 1430, Loss: 7.7077\n",
      "Epoch 1440, Loss: 7.5893\n",
      "Epoch 1450, Loss: 7.3476\n",
      "Epoch 1460, Loss: 8.2150\n",
      "Epoch 1470, Loss: 7.7753\n",
      "Epoch 1480, Loss: 7.2803\n",
      "Epoch 1490, Loss: 7.2637\n",
      "Epoch 1500, Loss: 7.5199\n",
      "Epoch 1510, Loss: 7.4254\n",
      "Epoch 1520, Loss: 7.8480\n",
      "Epoch 1530, Loss: 7.6393\n",
      "Epoch 1540, Loss: 7.2714\n",
      "Epoch 1550, Loss: 7.2746\n",
      "Epoch 1560, Loss: 7.1720\n",
      "Epoch 1570, Loss: 7.1561\n",
      "Epoch 1580, Loss: 7.3487\n",
      "Epoch 1590, Loss: 7.0427\n",
      "Epoch 1600, Loss: 7.0824\n",
      "Epoch 1610, Loss: 6.9923\n",
      "Epoch 1620, Loss: 6.9693\n",
      "Epoch 1630, Loss: 7.0876\n",
      "Epoch 1640, Loss: 7.0637\n",
      "Epoch 1650, Loss: 7.2295\n",
      "Epoch 1660, Loss: 7.0642\n",
      "Epoch 1670, Loss: 7.2234\n",
      "Epoch 1680, Loss: 7.1274\n",
      "Epoch 1690, Loss: 6.9615\n",
      "Epoch 1700, Loss: 6.9143\n",
      "Epoch 1710, Loss: 7.4801\n",
      "Epoch 1720, Loss: 7.1013\n",
      "Epoch 1730, Loss: 6.9670\n",
      "Epoch 1740, Loss: 6.7582\n",
      "Epoch 1750, Loss: 6.6946\n",
      "Epoch 1760, Loss: 6.9798\n",
      "Epoch 1770, Loss: 6.9814\n",
      "Epoch 1780, Loss: 7.3005\n",
      "Epoch 1790, Loss: 7.2052\n",
      "Epoch 1800, Loss: 7.0680\n",
      "Epoch 1810, Loss: 6.5696\n",
      "Epoch 1820, Loss: 6.7057\n",
      "Epoch 1830, Loss: 6.7271\n",
      "Epoch 1840, Loss: 6.6139\n",
      "Epoch 1850, Loss: 6.6074\n",
      "Epoch 1860, Loss: 6.4833\n",
      "Epoch 1870, Loss: 6.8393\n",
      "Epoch 1880, Loss: 7.0175\n",
      "Epoch 1890, Loss: 6.8208\n",
      "Epoch 1900, Loss: 7.3554\n",
      "Epoch 1910, Loss: 6.6475\n",
      "Epoch 1920, Loss: 6.4228\n",
      "Epoch 1930, Loss: 6.4137\n",
      "Epoch 1940, Loss: 6.4713\n",
      "Epoch 1950, Loss: 6.4517\n",
      "Epoch 1960, Loss: 6.4473\n",
      "Epoch 1970, Loss: 6.5804\n",
      "Epoch 1980, Loss: 6.6978\n",
      "Epoch 1990, Loss: 6.3852\n",
      "Epoch 2000, Loss: 6.4560\n",
      "Epoch 2010, Loss: 6.2197\n",
      "Epoch 2020, Loss: 6.2788\n",
      "Epoch 2030, Loss: 6.2363\n",
      "Epoch 2040, Loss: 6.2899\n",
      "Epoch 2050, Loss: 6.5721\n",
      "Epoch 2060, Loss: 6.3371\n",
      "Epoch 2070, Loss: 6.3878\n",
      "Epoch 2080, Loss: 6.3041\n",
      "Epoch 2090, Loss: 6.4335\n",
      "Epoch 2100, Loss: 6.3848\n",
      "Epoch 2110, Loss: 6.1547\n",
      "Epoch 2120, Loss: 6.3378\n",
      "Epoch 2130, Loss: 6.2466\n",
      "Epoch 2140, Loss: 6.3013\n",
      "Epoch 2150, Loss: 6.4007\n",
      "Epoch 2160, Loss: 6.3542\n",
      "Epoch 2170, Loss: 6.2860\n",
      "Epoch 2180, Loss: 6.6139\n",
      "Epoch 2190, Loss: 6.2775\n",
      "Epoch 2200, Loss: 6.1511\n",
      "Epoch 2210, Loss: 6.0067\n",
      "Epoch 2220, Loss: 6.2748\n",
      "Epoch 2230, Loss: 6.1646\n",
      "Epoch 2240, Loss: 6.2322\n",
      "Epoch 2250, Loss: 6.4231\n",
      "Epoch 2260, Loss: 6.4222\n",
      "Epoch 2270, Loss: 6.5008\n",
      "Epoch 2280, Loss: 6.0052\n",
      "Epoch 2290, Loss: 6.1032\n",
      "Epoch 2300, Loss: 6.0309\n",
      "Epoch 2310, Loss: 6.0511\n",
      "Epoch 2320, Loss: 5.9348\n",
      "Epoch 2330, Loss: 6.3260\n",
      "Epoch 2340, Loss: 6.4058\n",
      "Epoch 2350, Loss: 6.3364\n",
      "Epoch 2360, Loss: 6.4363\n",
      "Epoch 2370, Loss: 6.6009\n",
      "Epoch 2380, Loss: 6.4162\n",
      "Epoch 2390, Loss: 6.0289\n",
      "Epoch 2400, Loss: 5.8925\n",
      "Epoch 2410, Loss: 5.8929\n",
      "Epoch 2420, Loss: 5.9669\n",
      "Epoch 2430, Loss: 5.8289\n",
      "Epoch 2440, Loss: 5.8451\n",
      "Epoch 2450, Loss: 5.8074\n",
      "Epoch 2460, Loss: 6.0132\n",
      "Epoch 2470, Loss: 5.8355\n",
      "Epoch 2480, Loss: 5.9141\n",
      "Epoch 2490, Loss: 6.0039\n",
      "Epoch 2500, Loss: 6.0573\n",
      "Epoch 2510, Loss: 5.9165\n",
      "Epoch 2520, Loss: 5.9170\n",
      "Epoch 2530, Loss: 6.0817\n",
      "Epoch 2540, Loss: 5.9869\n",
      "Epoch 2550, Loss: 5.8334\n",
      "Epoch 2560, Loss: 5.9289\n",
      "Epoch 2570, Loss: 6.0853\n",
      "Early stopping at epoch 2578\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:29:50.951996Z",
     "start_time": "2024-12-03T12:29:50.514138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from function import metrics_to_dataframe\n",
    "\n",
    "# 加载最佳模型的状态字典\n",
    "model.load_state_dict(torch.load(\"tab_transformer_best_model_hidden1241.pth\", weights_only=True))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 对训练集进行预测\n",
    "    predictions = model(X_train_categ_tensor, X_train_cont_tensor)\n",
    "    # 对测试集进行预测\n",
    "    test_predictions = model(X_test_categ_tensor, X_test_cont_tensor)\n",
    "\n",
    "    # 将结果转换为DataFrame\n",
    "    tab_transformer_metrics = metrics_to_dataframe(\n",
    "        y_train_tensor.cpu().numpy(), predictions.cpu().numpy(),\n",
    "        y_test_tensor.cpu().numpy(), test_predictions.cpu().numpy(), \"TabTransformer\").round(3)\n",
    "    tab_transformer_metrics.to_csv('TabTransformer_metrics.csv', index=False)\n",
    "\n",
    "tab_transformer_metrics"
   ],
   "id": "caf816a60d26e411",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            model  R2_train  MAE_train  MAPE_train  RMSE_train  R2_test  \\\n",
       "0  TabTransformer     0.923      5.652       5.822      11.144     0.84   \n",
       "\n",
       "   MAE_test  MAPE_test  RMSE_test  \n",
       "0    10.888      15.56  16.617001  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TabTransformer</td>\n",
       "      <td>0.923</td>\n",
       "      <td>5.652</td>\n",
       "      <td>5.822</td>\n",
       "      <td>11.144</td>\n",
       "      <td>0.84</td>\n",
       "      <td>10.888</td>\n",
       "      <td>15.56</td>\n",
       "      <td>16.617001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:29:51.118774Z",
     "start_time": "2024-12-03T12:29:51.113143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存训练集和测试集的预测结果（包含真实值）\n",
    "tab_transformer_train = pd.DataFrame({'Actual': y_train_tensor.cpu().numpy().squeeze(), 'Predicted': predictions.cpu().numpy().squeeze()})\n",
    "tab_transformer_test = pd.DataFrame({'Actual': y_test_tensor.cpu().numpy().squeeze(), 'Predicted': test_predictions.cpu().numpy().squeeze()})\n",
    "\n",
    "tab_transformer_train.to_csv('tab_transformer_train.csv', index=False)\n",
    "tab_transformer_test.to_csv('tab_transformer_test.csv', index=False)"
   ],
   "id": "86de863b532e6d45",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
