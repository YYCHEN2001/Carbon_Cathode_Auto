{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 准备数据",
   "id": "483dc5fd0971e2b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T04:37:34.095046Z",
     "start_time": "2024-12-05T04:37:28.434515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "8874c47a571954c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T04:37:37.761049Z",
     "start_time": "2024-12-05T04:37:35.477025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../../data/dataset_reduced.csv\")\n",
    "data['target_class'] = pd.qcut(data['Cs'], q=10, labels=False)\n",
    "X = data.drop(['Cs', 'target_class'], axis=1)\n",
    "y = data['Cs']\n",
    "stratify_column = data['target_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=stratify_column)\n",
    "\n",
    "X_train_categ = X_train.iloc[:, 7].values  # 第九列为类别特征\n",
    "X_train_cont = np.delete(X_train, 7, axis=1)  # 删除第九列，其他为连续特征"
   ],
   "id": "544d2bb78075f78f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T04:37:39.129531Z",
     "start_time": "2024-12-05T04:37:38.992343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将 NumPy 数组转换为 PyTorch 张量\n",
    "X_train_categ_tensor = torch.tensor(X_train_categ, dtype=torch.long)  # 类别特征需要使用长整型\n",
    "X_train_categ_tensor = X_train_categ_tensor.unsqueeze(1).to(device)  # 在最后一个维度添加1\n",
    "X_train_cont_tensor = torch.tensor(X_train_cont, dtype=torch.float).to(device)  # 连续特征使用浮点型\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)  # 对于回归问题，通常使用浮点数\n",
    "y_train_tensor = y_train_tensor.unsqueeze(1).to(device)\n",
    "\n",
    "# 计算连续特征的均值和标准差\n",
    "mean = X_train_cont_tensor.mean(dim=0)\n",
    "std = X_train_cont_tensor.std(dim=0)\n",
    "continuous_mean_std = torch.stack([mean, std], dim=1).to(device)\n",
    "\n",
    "# 处理测试集\n",
    "X_test_categ = X_test.iloc[:, 7].values\n",
    "X_test_cont = np.delete(X_test, 7, axis=1)\n",
    "X_test_categ_tensor = torch.tensor(X_test_categ, dtype=torch.long)\n",
    "X_test_categ_tensor = X_test_categ_tensor.unsqueeze(1).to(device)\n",
    "X_test_cont_tensor = torch.tensor(X_test_cont, dtype=torch.float).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)\n",
    "y_test_tensor = y_test_tensor.unsqueeze(1).to(device)"
   ],
   "id": "3499816898be9093",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 定义模型",
   "id": "53feb800f58be3f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T04:37:48.610455Z",
     "start_time": "2024-12-05T04:37:47.454452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "from torch_function import MAE_Loss\n",
    "\n",
    "# 我们有9个特征，其中有1个类别特征，8个连续值特征\n",
    "# 类别特征每个有2个唯一值\n",
    "categories = (2,)\n",
    "num_continuous = 8\n",
    "\n",
    "# 初始化 TabTransformer 模型\n",
    "model = TabTransformer(\n",
    "    categories=categories,\n",
    "    num_continuous=num_continuous,\n",
    "    dim=18,  # 默认维度为32\n",
    "    dim_out=1,  # 回归问题的输出维度为1\n",
    "    depth=8,  # 默认深度为6\n",
    "    heads=8,  # 注意力机制的头数\n",
    "    attn_dropout=0.01,  # 注意力机制的dropout\n",
    "    ff_dropout=0.01,  # 前馈网络的的dropout\n",
    "    mlp_hidden_mults=(1, 4, 12, 1),  # MLP隐藏层的倍数\n",
    "    mlp_act=nn.ReLU(),  # MLP的激活函数, 默认为ReLU\n",
    "    continuous_mean_std=continuous_mean_std,  # 连续值的均值和标准差\n",
    ")\n",
    "\n",
    "# 将模型移动到 GPU\n",
    "model.to(device)\n",
    "\n",
    "# 初始化损失函数\n",
    "criterion = MAE_Loss().to(device)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ],
   "id": "f3b60050a04f7e4f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练模型",
   "id": "19f0115a86873316"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T04:38:18.619355Z",
     "start_time": "2024-12-05T04:37:50.248620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练循环\n",
    "num_epochs = 3000\n",
    "patience = 100  # 允许的最大连续未改进 epoch 数\n",
    "epochs_without_improvement = 0  # 连续未改进的 epoch 数\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    model.zero_grad()\n",
    "    outputs = model(X_train_categ_tensor, X_train_cont_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)  # 使用MSE损失函数\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss:.4f}')\n",
    "\n",
    "    # 计算验证损失\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_train_categ_tensor, X_train_cont_tensor).to(device)\n",
    "        y_train_tensor = y_train_tensor.to(device)\n",
    "        val_loss = criterion(y_val_pred, y_train_tensor).item()\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"tab_transformer_best_model_hidden1241.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break"
   ],
   "id": "8f283be2c8de26be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 73.0409\n",
      "Epoch 20, Loss: 31.8490\n",
      "Epoch 30, Loss: 30.7018\n",
      "Epoch 40, Loss: 31.4402\n",
      "Epoch 50, Loss: 30.2203\n",
      "Epoch 60, Loss: 29.8990\n",
      "Epoch 70, Loss: 29.7044\n",
      "Epoch 80, Loss: 29.2633\n",
      "Epoch 90, Loss: 28.6952\n",
      "Epoch 100, Loss: 27.8750\n",
      "Epoch 110, Loss: 26.4024\n",
      "Epoch 120, Loss: 24.0724\n",
      "Epoch 130, Loss: 22.3830\n",
      "Epoch 140, Loss: 21.6467\n",
      "Epoch 150, Loss: 21.2129\n",
      "Epoch 160, Loss: 20.8914\n",
      "Epoch 170, Loss: 20.5785\n",
      "Epoch 180, Loss: 20.4112\n",
      "Epoch 190, Loss: 20.1578\n",
      "Epoch 200, Loss: 19.7972\n",
      "Epoch 210, Loss: 19.5913\n",
      "Epoch 220, Loss: 19.1747\n",
      "Epoch 230, Loss: 18.6741\n",
      "Epoch 240, Loss: 18.3734\n",
      "Epoch 250, Loss: 17.8750\n",
      "Epoch 260, Loss: 17.6814\n",
      "Epoch 270, Loss: 17.0597\n",
      "Epoch 280, Loss: 16.5700\n",
      "Epoch 290, Loss: 16.2902\n",
      "Epoch 300, Loss: 15.7836\n",
      "Epoch 310, Loss: 15.4792\n",
      "Epoch 320, Loss: 15.0074\n",
      "Epoch 330, Loss: 14.5281\n",
      "Epoch 340, Loss: 14.3703\n",
      "Epoch 350, Loss: 13.8803\n",
      "Epoch 360, Loss: 13.7615\n",
      "Epoch 370, Loss: 13.7151\n",
      "Epoch 380, Loss: 13.0510\n",
      "Epoch 390, Loss: 12.9419\n",
      "Epoch 400, Loss: 12.6904\n",
      "Epoch 410, Loss: 12.4237\n",
      "Epoch 420, Loss: 12.2317\n",
      "Epoch 430, Loss: 11.9875\n",
      "Epoch 440, Loss: 11.7483\n",
      "Epoch 450, Loss: 11.5510\n",
      "Epoch 460, Loss: 11.5411\n",
      "Epoch 470, Loss: 11.1497\n",
      "Epoch 480, Loss: 11.0910\n",
      "Epoch 490, Loss: 11.0144\n",
      "Epoch 500, Loss: 11.1472\n",
      "Epoch 510, Loss: 10.7398\n",
      "Epoch 520, Loss: 11.2377\n",
      "Epoch 530, Loss: 10.8154\n",
      "Epoch 540, Loss: 10.8793\n",
      "Epoch 550, Loss: 10.7585\n",
      "Epoch 560, Loss: 10.3420\n",
      "Epoch 570, Loss: 10.4555\n",
      "Epoch 580, Loss: 10.5133\n",
      "Epoch 590, Loss: 10.3464\n",
      "Epoch 600, Loss: 10.0733\n",
      "Epoch 610, Loss: 9.9348\n",
      "Epoch 620, Loss: 9.9300\n",
      "Epoch 630, Loss: 10.2267\n",
      "Epoch 640, Loss: 9.7203\n",
      "Epoch 650, Loss: 9.7671\n",
      "Epoch 660, Loss: 10.0083\n",
      "Epoch 670, Loss: 9.6043\n",
      "Epoch 680, Loss: 9.5562\n",
      "Epoch 690, Loss: 10.2330\n",
      "Epoch 700, Loss: 10.0019\n",
      "Epoch 710, Loss: 9.4370\n",
      "Epoch 720, Loss: 9.2198\n",
      "Epoch 730, Loss: 9.1085\n",
      "Epoch 740, Loss: 9.2920\n",
      "Epoch 750, Loss: 9.0077\n",
      "Epoch 760, Loss: 9.2395\n",
      "Epoch 770, Loss: 8.9427\n",
      "Epoch 780, Loss: 8.8971\n",
      "Epoch 790, Loss: 8.7261\n",
      "Epoch 800, Loss: 9.0518\n",
      "Epoch 810, Loss: 8.5884\n",
      "Epoch 820, Loss: 8.7899\n",
      "Epoch 830, Loss: 8.9310\n",
      "Epoch 840, Loss: 9.1265\n",
      "Epoch 850, Loss: 8.6232\n",
      "Epoch 860, Loss: 8.6534\n",
      "Epoch 870, Loss: 8.3088\n",
      "Epoch 880, Loss: 8.3939\n",
      "Epoch 890, Loss: 8.0572\n",
      "Epoch 900, Loss: 8.2026\n",
      "Epoch 910, Loss: 8.6673\n",
      "Epoch 920, Loss: 8.7924\n",
      "Epoch 930, Loss: 7.8877\n",
      "Epoch 940, Loss: 7.8461\n",
      "Epoch 950, Loss: 7.6749\n",
      "Epoch 960, Loss: 8.1368\n",
      "Epoch 970, Loss: 7.8996\n",
      "Epoch 980, Loss: 7.7739\n",
      "Epoch 990, Loss: 7.6703\n",
      "Epoch 1000, Loss: 8.2246\n",
      "Epoch 1010, Loss: 7.8549\n",
      "Epoch 1020, Loss: 7.2838\n",
      "Epoch 1030, Loss: 7.2990\n",
      "Epoch 1040, Loss: 7.1238\n",
      "Epoch 1050, Loss: 7.0785\n",
      "Epoch 1060, Loss: 7.4869\n",
      "Epoch 1070, Loss: 7.2356\n",
      "Epoch 1080, Loss: 7.3481\n",
      "Epoch 1090, Loss: 7.2814\n",
      "Epoch 1100, Loss: 7.4994\n",
      "Epoch 1110, Loss: 7.8876\n",
      "Epoch 1120, Loss: 7.4394\n",
      "Epoch 1130, Loss: 7.2281\n",
      "Epoch 1140, Loss: 6.8250\n",
      "Epoch 1150, Loss: 7.1726\n",
      "Epoch 1160, Loss: 7.9511\n",
      "Epoch 1170, Loss: 7.6689\n",
      "Epoch 1180, Loss: 6.8771\n",
      "Epoch 1190, Loss: 6.6926\n",
      "Epoch 1200, Loss: 7.1086\n",
      "Epoch 1210, Loss: 6.8152\n",
      "Epoch 1220, Loss: 6.7453\n",
      "Epoch 1230, Loss: 6.6580\n",
      "Epoch 1240, Loss: 8.3921\n",
      "Epoch 1250, Loss: 7.1529\n",
      "Epoch 1260, Loss: 6.7373\n",
      "Epoch 1270, Loss: 6.8419\n",
      "Epoch 1280, Loss: 7.1481\n",
      "Epoch 1290, Loss: 6.7720\n",
      "Epoch 1300, Loss: 6.4238\n",
      "Epoch 1310, Loss: 6.4557\n",
      "Epoch 1320, Loss: 6.7752\n",
      "Epoch 1330, Loss: 7.1586\n",
      "Epoch 1340, Loss: 6.9762\n",
      "Epoch 1350, Loss: 6.5906\n",
      "Epoch 1360, Loss: 6.4135\n",
      "Epoch 1370, Loss: 6.1890\n",
      "Epoch 1380, Loss: 6.4201\n",
      "Epoch 1390, Loss: 6.2776\n",
      "Epoch 1400, Loss: 7.4586\n",
      "Epoch 1410, Loss: 6.2276\n",
      "Epoch 1420, Loss: 6.1654\n",
      "Epoch 1430, Loss: 6.2047\n",
      "Epoch 1440, Loss: 6.5513\n",
      "Epoch 1450, Loss: 6.0501\n",
      "Epoch 1460, Loss: 6.0714\n",
      "Epoch 1470, Loss: 6.0218\n",
      "Epoch 1480, Loss: 6.4068\n",
      "Epoch 1490, Loss: 6.5373\n",
      "Epoch 1500, Loss: 6.2200\n",
      "Epoch 1510, Loss: 6.0345\n",
      "Epoch 1520, Loss: 6.2398\n",
      "Epoch 1530, Loss: 6.1699\n",
      "Epoch 1540, Loss: 7.1672\n",
      "Epoch 1550, Loss: 6.2650\n",
      "Epoch 1560, Loss: 6.7412\n",
      "Early stopping at epoch 1564\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T04:38:21.489984Z",
     "start_time": "2024-12-05T04:38:20.331451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from function import metrics_to_dataframe\n",
    "\n",
    "# 加载最佳模型的状态字典\n",
    "model.load_state_dict(torch.load(\"tab_transformer_best_model_hidden1241.pth\", weights_only=True))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 对训练集进行预测\n",
    "    predictions = model(X_train_categ_tensor, X_train_cont_tensor)\n",
    "    # 对测试集进行预测\n",
    "    test_predictions = model(X_test_categ_tensor, X_test_cont_tensor)\n",
    "\n",
    "    # 将结果转换为DataFrame\n",
    "    tab_transformer_metrics = metrics_to_dataframe(\n",
    "        y_train_tensor.cpu().numpy(), predictions.cpu().numpy(),\n",
    "        y_test_tensor.cpu().numpy(), test_predictions.cpu().numpy(), \"TabTransformer\").round(3)\n",
    "    tab_transformer_metrics.to_csv('TabTransformer_metrics.csv', index=False)\n",
    "\n",
    "tab_transformer_metrics"
   ],
   "id": "caf816a60d26e411",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            model  R2_train  MAE_train  MAPE_train  RMSE_train  R2_test  \\\n",
       "0  TabTransformer     0.921      5.899       6.775      11.254    0.855   \n",
       "\n",
       "   MAE_test  MAPE_test  RMSE_test  \n",
       "0     9.748      13.66     15.779  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TabTransformer</td>\n",
       "      <td>0.921</td>\n",
       "      <td>5.899</td>\n",
       "      <td>6.775</td>\n",
       "      <td>11.254</td>\n",
       "      <td>0.855</td>\n",
       "      <td>9.748</td>\n",
       "      <td>13.66</td>\n",
       "      <td>15.779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T04:38:27.447919Z",
     "start_time": "2024-12-05T04:38:27.443203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存训练集和测试集的预测结果（包含真实值）\n",
    "tab_transformer_train = pd.DataFrame({'Actual': y_train_tensor.cpu().numpy().squeeze(), 'Predicted': predictions.cpu().numpy().squeeze()})\n",
    "tab_transformer_test = pd.DataFrame({'Actual': y_test_tensor.cpu().numpy().squeeze(), 'Predicted': test_predictions.cpu().numpy().squeeze()})\n",
    "\n",
    "tab_transformer_train.to_csv('tab_transformer_train.csv', index=False)\n",
    "tab_transformer_test.to_csv('tab_transformer_test.csv', index=False)"
   ],
   "id": "86de863b532e6d45",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
